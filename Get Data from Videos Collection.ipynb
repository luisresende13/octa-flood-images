{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38f72f68-397a-4495-b523-07ddb8ee32f7",
   "metadata": {},
   "source": [
    "# Download videos, images and datasets from Octa City's collection of flood videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391effa1-60e5-4a73-982e-7db30b0f595a",
   "metadata": {},
   "source": [
    "#### Set credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ef9d35f-6735-4649-a7e0-b7bb161255b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mongo_connection_string = 'your_mongo_connection_string'\n",
    "# google_credentials_path = 'path/to/your/google_service_account_credential.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcc769b-17c4-4d43-86a0-74786bef9302",
   "metadata": {},
   "source": [
    "## 1. Download videos dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36679d63-8b02-4d3d-9600-ab7a009a3e92",
   "metadata": {},
   "source": [
    "Download `Videos Localizados` mongo collections as pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0e572754-6118-4d04-b53d-2e16c575715d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video files in dataset: 62017\n",
      "Total mega bytes (MBs): 78.405\n",
      "Time to download: 16.6\n",
      "Time to save dataframe: 2.5\n",
      "Time Total: 19.7 s\n"
     ]
    }
   ],
   "source": [
    "from modules.mongo import MongoDB\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import json\n",
    "from time import time\n",
    "\n",
    "videos_dataset_path = 'data/datasets/videos.csv'\n",
    "\n",
    "# Get MongoDB collection as list of objects\n",
    "s1 = time()\n",
    "mongo = MongoDB(mongo_connection_string)\n",
    "data = mongo.get('Waterbag', 'Videos Localizados')\n",
    "\n",
    "# Convert to pandas dataframe\n",
    "s2 = time()\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert 'tags' json field to string\n",
    "df['tags'] = df['tags'].apply(json.dumps)\n",
    "\n",
    "# Save as pandas dataframe\n",
    "s3 = time()\n",
    "df.to_csv(videos_dataset_path, index=False)\n",
    "\n",
    "s4 = time()\n",
    "total_mega_bytes = df['blob_size'].replace('', 0).astype('int').sum() / 1e9\n",
    "print('Video files in dataset:', df.shape[0])\n",
    "print('Total mega bytes (MBs):', round(total_mega_bytes, 3))\n",
    "print('Time to download:', round(s2 - s1, 1))\n",
    "print('Time to save dataframe:', round(s4 - s3, 1))\n",
    "print('Time Total:', round(s4 - s1, 1), 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34f784a-36d0-4ea2-a382-75127c67f1b9",
   "metadata": {},
   "source": [
    "#### Report videos dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a87caa3-b9db-4f46-ac6a-7fc861c747a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vídeos assistidos: 708\n",
      "Vídeos rotulados: 608\n",
      "Câmeras com rótulos: 47\n",
      "Vídeos de câmeras com rótulos: 9159\n",
      "\n",
      "ROWS WITH MISSING VALUES:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>blob_name</th>\n",
       "      <th>blob_size</th>\n",
       "      <th>bucket_name</th>\n",
       "      <th>file_name</th>\n",
       "      <th>code</th>\n",
       "      <th>n_folders</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>folder_structure</th>\n",
       "      <th>folder</th>\n",
       "      <th>tags</th>\n",
       "      <th>url</th>\n",
       "      <th>api_url</th>\n",
       "      <th>bucket</th>\n",
       "      <th>seen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18462</th>\n",
       "      <td>6504ff5b874b309c35491888</td>\n",
       "      <td>comando/CODE2017 2023-04-14 17-41-36.webm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[alagamento, bolsão]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>flood-videos-stamped</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18463</th>\n",
       "      <td>6505012a874b309c35491889</td>\n",
       "      <td>comando/lâmina/101084/CODE2205 2023-08-20 12-0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[lâmina]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>flood-videos-stamped</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18464</th>\n",
       "      <td>65050136874b309c3549188a</td>\n",
       "      <td>comando/lâmina/101084/CODE2206 2023-08-20 12-1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[lâmina]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>flood-videos-stamped</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            _id  \\\n",
       "18462  6504ff5b874b309c35491888   \n",
       "18463  6505012a874b309c35491889   \n",
       "18464  65050136874b309c3549188a   \n",
       "\n",
       "                                               blob_name  blob_size  \\\n",
       "18462          comando/CODE2017 2023-04-14 17-41-36.webm        NaN   \n",
       "18463  comando/lâmina/101084/CODE2205 2023-08-20 12-0...        NaN   \n",
       "18464  comando/lâmina/101084/CODE2206 2023-08-20 12-1...        NaN   \n",
       "\n",
       "      bucket_name file_name  code  n_folders timestamp folder_structure  \\\n",
       "18462         NaN       NaN   NaN        NaN       NaN              NaN   \n",
       "18463         NaN       NaN   NaN        NaN       NaN              NaN   \n",
       "18464         NaN       NaN   NaN        NaN       NaN              NaN   \n",
       "\n",
       "      folder                  tags  url api_url                bucket   seen  \n",
       "18462    NaN  [alagamento, bolsão]  NaN     NaN  flood-videos-stamped  False  \n",
       "18463    NaN              [lâmina]  NaN     NaN  flood-videos-stamped  False  \n",
       "18464    NaN              [lâmina]  NaN     NaN  flood-videos-stamped  False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seen = df['seen'].sum()\n",
    "tagged = ~df['tags'].isin([[]])\n",
    "cameras_with_labels = df[tagged]['code'].unique()\n",
    "videos_from_cameras_with_labels = df[df['code'].isin(cameras_with_labels)]\n",
    "rows_with_missin_values = df[df['timestamp'].isna()]\n",
    "\n",
    "print('\\nVídeos assistidos:', seen)\n",
    "print('Vídeos rotulados:', tagged.sum())\n",
    "print('Câmeras com rótulos:', len(cameras_with_labels))\n",
    "print('Vídeos de câmeras com rótulos:', len(videos_from_cameras_with_labels))\n",
    "\n",
    "print('\\nROWS WITH MISSING VALUES:')\n",
    "display(rows_with_missin_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9c7a24-1d00-4342-bae6-e6695e114e62",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Reload videos dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c08ee6f0-afee-4d89-8415-395b2db57f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "videos_dataset_path = 'data/datasets/videos.csv'\n",
    "df = pd.read_csv(videos_dataset_path)\n",
    "\n",
    "# Preprocessing\n",
    "df['tags'] = df['tags'].apply(json.loads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7311e48a-f2d9-4401-b849-36ff3f40c993",
   "metadata": {},
   "source": [
    "#### Preprocessing of videos dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "933138af-ccd4-459a-8c6e-c0465823754f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "df_custom = df.copy()\n",
    "df_custom['bucket_name'] = 'flood-video-collection'\n",
    "df_custom['blob_name'] = df_custom['blob_name'].str.replace('.webm', '.mp4') # reproduce the .mp4 collection using the .webm collection\n",
    "df_custom.dropna(subset=['timestamp'], inplace=True) # Drop rows with missing values for `timestmaps`field"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24eea128-e5f5-4ce7-be07-b4de5eb2c29d",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Download video files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c0a80f-96db-4ee3-9cf3-e3018fe6ed2d",
   "metadata": {},
   "source": [
    "#### Import utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52a20a51-b0cd-4ea2-944d-2897ecd55841",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.octa_video_util import filter_by_query, _assign_tag\n",
    "from modules.octa_video_util import VideoDownloader, VideoFrameExtractor\n",
    "from modules.octa_video_util import buildImageDataset, buildImageDatasetThreads\n",
    "from modules.octa_video_util import copy_images_to_folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdc9d06-255e-45b9-8eb5-cfecdcf0db3e",
   "metadata": {},
   "source": [
    "#### Download videos with optional query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cc2fcc56-ab7a-4c51-8e04-4bf972e8bcd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE! 708/708 files downloaded.0%)\n"
     ]
    }
   ],
   "source": [
    "# from modules.octa_video_util import VideoDownloader\n",
    "\n",
    "target_directory = 'data/videos'\n",
    "bucket_name = 'flood-video-collection'\n",
    "\n",
    "# query_params = {'code': [101, 102, 103], 'seen': [True, False]} \n",
    "query_params = {'seen': [True]} \n",
    "\n",
    "overwrite = False\n",
    "max_threads = 30\n",
    "\n",
    "downloader = VideoDownloader(df_custom, target_directory, google_credentials_path, max_threads)\n",
    "downloader.download_videos(query_params, overwrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735d2479-6fad-422b-a227-639fecf78639",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Extract and save image files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f260c0-7ca4-4225-b2b3-17f4ced11bfb",
   "metadata": {},
   "source": [
    "#### Extract images from video files (with optional query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34244ea9-66fb-4f39-87a0-31f707e13bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 709/708 rows (100.14%)/videos\\polygons/manual/72/77/CODE77 2023-02-08 16-20-00.mp4p4-00-15.mp4mp4Extracted 45/45 frames from data/videos\\polygons/comando/alagamento/0/1639/CODE1639 2023-08-28 23-35-03.mp4\r"
     ]
    }
   ],
   "source": [
    "# from modules.octa_video_util import VideoFrameExtractor\n",
    "# from modules.octa_video_util import filter_by_query\n",
    "\n",
    "base_directory = 'data/videos'\n",
    "target_directory = 'data/images'\n",
    "\n",
    "# query_params = {'code': [101, 102, 103], 'seen': [True, False]} \n",
    "query_params = {'seen': [True]} \n",
    "\n",
    "df_filtered = filter_by_query(df_custom, query_params).copy()\n",
    "overwrite = False\n",
    "MAX_THREADS = 10  # Be careful\n",
    "\n",
    "frame_extractor = VideoFrameExtractor(df_filtered, base_directory, target_directory, MAX_THREADS)\n",
    "frame_extractor.extract_frames(overwrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4cb053-6328-4a6e-8dd8-eafc63b0d576",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Build images dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed695d5-27aa-4b16-8965-89ee65631651",
   "metadata": {},
   "source": [
    "Create the dataset of images from the video files in `base_directory` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbfb9c4-4ae4-4854-ab4f-a527341a009d",
   "metadata": {},
   "source": [
    "Obs: To update to the latest 'tags' and 'seen' values, re-download the 'videos' dataset and pass it down to `buildImageDataset` or `buildImageDatasetThreads` below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a422bdf0-7978-4e48-8603-c62fbdefc0a7",
   "metadata": {},
   "source": [
    "#### Build images dataset from video files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3528ccc-4015-476b-a205-10b0f3686f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed videos: 708/708 (100.0) %\n",
      "\n",
      "Image dataset shape: (29356, 10)\n"
     ]
    }
   ],
   "source": [
    "# from modules.octa_video_util import buildImageDataset\n",
    "# from modules.octa_video_util import _assign_tag\n",
    "\n",
    "dataset = df_custom.copy()\n",
    "base_directory = 'data/videos'\n",
    "images_dataset_path = 'data/datasets/images.csv'\n",
    "fps = 3\n",
    "\n",
    "# Build images dataset\n",
    "df_images =  buildImageDataset(dataset, base_directory, fps=fps)\n",
    "\n",
    "# Save images dataset\n",
    "df_images.to_csv(images_dataset_path, index=False)\n",
    "\n",
    "# Print results\n",
    "print('Image dataset shape:', df_images.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5319726a-f3da-41e4-a440-79e6e430968e",
   "metadata": {},
   "source": [
    "#### Build images dataset from video files with threads (Faster version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4b8aac5-c536-42d9-a19b-6d00432a1775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed videos: 708/708 (100.0) %\n",
      "\n",
      "Image dataset shape: (29356, 10)\n"
     ]
    }
   ],
   "source": [
    "# from modules.octa_video_util import buildImageDatasetThreads\n",
    "# from modules.octa_video_util import _assign_tag\n",
    "\n",
    "dataset = df_custom.copy()\n",
    "base_directory = 'data/videos'\n",
    "images_dataset_path = 'data/datasets/images.csv'\n",
    "fps = 3\n",
    "print_each = 50\n",
    "max_threads = 10\n",
    "\n",
    "df_images = buildImageDatasetThreads(dataset, base_directory, fps, print_each, max_threads)\n",
    "\n",
    "# Save images dataset\n",
    "df_images.to_csv(images_dataset_path, index=False)\n",
    "\n",
    "# Print results\n",
    "print('\\nImage dataset shape:', df_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1acfbc-e3da-4b72-94c7-e939520cec3c",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Reload images dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dd947e5-a58c-4146-95df-da4445c2cc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "images_dataset_path = 'data/datasets/images.csv'\n",
    "df_images = pd.read_csv(images_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a277a3f-a1a3-498f-8902-faa33d254e8f",
   "metadata": {},
   "source": [
    "#### Create 'tag' field from multiple tags based on tag priority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f30c7694-0b21-4a8b-a196-141e87720581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagens assistidas (de videos baixados): 29356 / 29356\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tag\n",
       "poça          19877\n",
       "normal         4889\n",
       "lâmina         3661\n",
       "alagamento      863\n",
       "bolsão           66\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create unique tag column based on class priority list\n",
    "default_tag = 'normal'\n",
    "tags_priority_list = ['alagamento', 'bolsão', 'lâmina', 'poça', 'transbordo']\n",
    "\n",
    "df_images['tag'] = df_images['tags'].apply(lambda tags_list: _assign_tag(tags_list, tags_priority_list, default_tag))\n",
    "\n",
    "print('Imagens assistidas (de videos baixados):', df_images['seen'].sum(), '/', len(df_images))\n",
    "print()\n",
    "display(df_images.tag.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861a9653-7594-49a9-8594-ad0118d8d743",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Example: Train and test split + Copying images into train and test folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a200b9-2dfc-40df-8019-f8b17ebf326e",
   "metadata": {},
   "source": [
    "#### Custom sampling of images (Example usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f84594e9-e33f-46b6-a8ba-f50fc8af91c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 216\n",
      "Test samples: 84\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flood</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train\n",
       "flood       \n",
       "1        127\n",
       "0         89"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flood</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       test\n",
       "flood      \n",
       "0        54\n",
       "1        30"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from modules.octa_video_util import _filter_by_query\n",
    "\n",
    "random_state = 0\n",
    "max_samples = 300\n",
    "minority_classes = ['lâmina', 'bolsão', 'alagamento']\n",
    "class_col = 'tag'\n",
    "target_col = 'flood'\n",
    "groups_col = 'code'\n",
    "\n",
    "# Custom pre-sample of images dataset\n",
    "# query_params = {'code': [101, 102, 103], 'seen': [True, False]}\n",
    "query_params = {}\n",
    "df_presample = filter_by_query(df_images, query_params).copy()\n",
    "df_presample.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Create target variable for binary classification\n",
    "df_presample[target_col] = df_presample[class_col].isin(minority_classes).astype(int)\n",
    "\n",
    "# Get x and y\n",
    "x = df_presample.drop(target_col, axis=1)\n",
    "y = df_presample[target_col]\n",
    "groups = df_presample[groups_col]\n",
    "\n",
    "# Custom under sampling\n",
    "minority_samples = (y == 1).sum()\n",
    "y_minority_sample = y[y == 0].sample(n=minority_samples, replace=False, random_state=random_state)\n",
    "y_res = pd.concat([y_minority_sample, y[y == 1]], axis=0).sample(max_samples, replace=True, random_state=random_state)\n",
    "x_res = x.loc[y_res.index]\n",
    "groups_res = groups.loc[y_res.index]\n",
    "\n",
    "# Stratified group KFold split\n",
    "sgkf = StratifiedGroupKFold(n_splits=3, shuffle=True, random_state=random_state)\n",
    "for i, (train_index, test_index) in enumerate(sgkf.split(x_res, y_res, groups_res)):\n",
    "    break\n",
    "\n",
    "X_train = x_res.iloc[train_index]\n",
    "X_test = x_res.iloc[test_index]\n",
    "\n",
    "Y_train = y_res.iloc[train_index]\n",
    "Y_test = y_res.iloc[test_index]\n",
    "\n",
    "print('Train samples:',len(train_index))\n",
    "print('Test samples:', len(test_index))\n",
    "\n",
    "display(Y_train.value_counts().to_frame('train'))\n",
    "display(Y_test.value_counts().to_frame('test'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63caf0c0-93b2-4d44-9597-c8be80a3487f",
   "metadata": {},
   "source": [
    "#### Copy images from `train_index`and `test_index` into structured 'train' and 'test' folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6065dcb-0426-4961-8cd2-f32d43b3da3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying images to train folders:\n",
      "Processed 216/216 files (100.00%) - Found: 56/216\n",
      "Copying images to test folders:\n",
      "Processed 84/84 files (100.00%) - Found: 66/216\r"
     ]
    }
   ],
   "source": [
    "from modules.octa_video_util import copy_images_to_folders\n",
    "\n",
    "base_directory = 'data/images'\n",
    "target_directory = 'data/samples/1'\n",
    "dataset = df_presample.loc[y_res.index].reset_index(drop=True).copy()\n",
    "train_indexes = list(train_index)\n",
    "test_indexes = list(test_index)\n",
    "\n",
    "file_path_field = 'file_path'\n",
    "label_field = 'flood'\n",
    "\n",
    "copy_images_to_folders(base_directory, target_directory, dataset, train_indexes, test_indexes, file_path_field=file_path_field, tag_field=label_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59fbce88-2455-465a-99dc-7394d46a6d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag\n",
       "poça    216\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_presample.loc[train_index]['tag'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
