{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38f72f68-397a-4495-b523-07ddb8ee32f7",
   "metadata": {},
   "source": [
    "# Download videos, images and datasets from Octa City's collection of flood videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391effa1-60e5-4a73-982e-7db30b0f595a",
   "metadata": {},
   "source": [
    "#### Set credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ef9d35f-6735-4649-a7e0-b7bb161255b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mongo_connection_string = 'your_mongo_connection_string' \n",
    "# google_credentials_path = 'path/to/your/service_account_credential.json'\n",
    "\n",
    "mongo_connection_string = 'mongodb+srv://luisresende13:Gaia0333@pluvia-cluster.ea8fb4s.mongodb.net/?retryWrites=true&w=majority' \n",
    "google_credentials_path = '../../Flask APIs/cams-rio/auth/octacity-iduff.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcc769b-17c4-4d43-86a0-74786bef9302",
   "metadata": {},
   "source": [
    "## 1. Download videos dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36679d63-8b02-4d3d-9600-ab7a009a3e92",
   "metadata": {},
   "source": [
    "Download `Videos Localizados` mongo collections as pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3008f50-d742-4d4c-9c6a-e7df6963edfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video files in dataset: 62017\n",
      "Total mega bytes (MBs): 78.405\n",
      "Time to download: 7.8\n",
      "Time to save dataframe: 1.9\n",
      "Time Total: 10.3 s\n"
     ]
    }
   ],
   "source": [
    "from modules.mongo import MongoDB\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import json\n",
    "from time import time\n",
    "\n",
    "db = 'Waterbag'\n",
    "coll = 'Videos Localizados'\n",
    "videos_dataset_path = 'data/datasets/videos.csv'\n",
    "\n",
    "# Get MongoDB collection as list of objects\n",
    "s1 = time()\n",
    "mongo = MongoDB(mongo_connection_string)\n",
    "data = mongo.get(db, coll)\n",
    "\n",
    "# Convert to pandas dataframe\n",
    "s2 = time()\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert 'tags' json field to string\n",
    "df['tags'] = df['tags'].apply(json.dumps)\n",
    "\n",
    "# Save as pandas dataframe\n",
    "s3 = time()\n",
    "df.to_csv(videos_dataset_path, index=False)\n",
    "\n",
    "s4 = time()\n",
    "total_mega_bytes = df['blob_size'].replace('', 0).astype('int').sum() / 1e9\n",
    "print('Video files in dataset:', df.shape[0])\n",
    "print('Total mega bytes (MBs):', round(total_mega_bytes, 3))\n",
    "print('Time to download:', round(s2 - s1, 1))\n",
    "print('Time to save dataframe:', round(s4 - s3, 1))\n",
    "print('Time Total:', round(s4 - s1, 1), 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34f784a-36d0-4ea2-a382-75127c67f1b9",
   "metadata": {},
   "source": [
    "#### Report videos dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31a22218-326a-45f9-8d08-59ed72609499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Videos: 62017\n",
      "Vídeos assistidos: 14680\n",
      "Vídeos rotulados: 5592\n",
      "Câmeras com rótulos: 406\n",
      "Vídeos de câmeras com rótulos: 38575\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TAGS IN VIDEOS SEEN\n",
       "normal        14142\n",
       "alagamento      538\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROWS WITH MISSING VALUES:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>blob_name</th>\n",
       "      <th>blob_size</th>\n",
       "      <th>bucket_name</th>\n",
       "      <th>file_name</th>\n",
       "      <th>code</th>\n",
       "      <th>n_folders</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>folder_structure</th>\n",
       "      <th>folder</th>\n",
       "      <th>tags</th>\n",
       "      <th>url</th>\n",
       "      <th>api_url</th>\n",
       "      <th>bucket</th>\n",
       "      <th>seen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [_id, blob_name, blob_size, bucket_name, file_name, code, n_folders, timestamp, folder_structure, folder, tags, url, api_url, bucket, seen]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total = len(df)\n",
    "seen = df['seen'].sum()\n",
    "tagged = df['tags'].apply(json.loads).apply(len) != 0\n",
    "cameras_with_labels = df[tagged]['code'].unique()\n",
    "videos_from_cameras_with_labels = df[df['code'].isin(cameras_with_labels)]\n",
    "rows_with_missin_values = df[df['timestamp'].isna()]\n",
    "\n",
    "print('Videos:', total)\n",
    "print('Vídeos assistidos:', seen)\n",
    "print('Vídeos rotulados:', tagged.sum())\n",
    "print('Câmeras com rótulos:', len(cameras_with_labels))\n",
    "print('Vídeos de câmeras com rótulos:', len(videos_from_cameras_with_labels))\n",
    "\n",
    "from modules.octa_video_util import _assign_tag\n",
    "default_tag = 'normal'\n",
    "tags_priority_list = ['alagamento', 'bolsão', 'lâmina']\n",
    "\n",
    "video_tags = df[df['seen']]['tags'].apply(lambda tags_list: _assign_tag(tags_list, tags_priority_list, default_tag))\n",
    "print()\n",
    "display(video_tags.rename('TAGS IN VIDEOS SEEN').value_counts())\n",
    "\n",
    "print('\\nROWS WITH MISSING VALUES:')\n",
    "display(rows_with_missin_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9c7a24-1d00-4342-bae6-e6695e114e62",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Reload videos dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f4c3e65-d611-49cc-831f-ab2c6009f3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "videos_dataset_path = 'data/datasets/videos.csv'\n",
    "df = pd.read_csv(videos_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7311e48a-f2d9-4401-b849-36ff3f40c993",
   "metadata": {},
   "source": [
    "#### Preprocessing of videos dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "933138af-ccd4-459a-8c6e-c0465823754f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "from modules.octa_video_util import _assign_tag\n",
    "\n",
    "default_tag = 'normal'\n",
    "tags_priority_list = ['alagamento', 'bolsão', 'lâmina']\n",
    "\n",
    "df['tags'] = df['tags'].apply(json.loads)\n",
    "df['tag'] = df['tags'].apply(lambda tags_list: _assign_tag(tags_list, tags_priority_list, default_tag))\n",
    "df['flood'] = df['tag'].isin(['lâmina', 'bolsão', 'alagamento']).astype(int)\n",
    "\n",
    "import json\n",
    "\n",
    "df_custom = df.copy()\n",
    "df_custom['bucket_name'] = 'flood-video-collection'\n",
    "df_custom['blob_name'] = df_custom['blob_name'].str.replace('.webm', '.mp4') # reproduce the .mp4 collection using the .webm collection\n",
    "df_custom.dropna(subset=['timestamp'], inplace=True) # Drop rows with missing values for `timestmaps` field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7050576e-3d20-4502-a788-1bb4e95cf229",
   "metadata": {},
   "source": [
    "#### Report videos dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0f33f0d-ea4c-4839-b4e9-8359ded05d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag\n",
       "normal        59295\n",
       "bolsão         1174\n",
       "lâmina         1009\n",
       "alagamento      539\n",
       "Name: All Videos, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tag\n",
       "normal        11965\n",
       "bolsão         1174\n",
       "lâmina         1003\n",
       "alagamento      538\n",
       "Name: Seen Videos Only, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "flood\n",
       "0    59295\n",
       "1     2722\n",
       "Name: Flood, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Videos seen: 14680\n",
      "\n",
      "Cameras seen with positive samples: 144\n",
      "Cameras seen with negative samples: 473\n",
      "Cameras seen total: 473\n"
     ]
    }
   ],
   "source": [
    "df_seen = df[df['seen']]\n",
    "\n",
    "codes = df_seen['code'].unique()\n",
    "codes_1 = df_seen[df_seen['flood'] == 1]['code'].unique()\n",
    "codes_0 = df_seen[df_seen['flood'] == 0]['code'].unique()\n",
    "\n",
    "display(df['tag'].value_counts().rename('All Videos'))\n",
    "print()\n",
    "display(df_seen['tag'].value_counts().rename('Seen Videos Only'))\n",
    "print()\n",
    "display(df['flood'].value_counts().rename('Flood'))\n",
    "\n",
    "print()\n",
    "print('Videos seen:', len(df_seen))\n",
    "print()\n",
    "print('Cameras seen with positive samples:', len(codes_1))\n",
    "print('Cameras seen with negative samples:', len(codes_0))\n",
    "print('Cameras seen total:', len(codes))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24eea128-e5f5-4ce7-be07-b4de5eb2c29d",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Download video files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c0a80f-96db-4ee3-9cf3-e3018fe6ed2d",
   "metadata": {},
   "source": [
    "#### Import utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52a20a51-b0cd-4ea2-944d-2897ecd55841",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.octa_video_util import filter_by_query, _assign_tag\n",
    "from modules.octa_video_util import VideoDownloader, VideoFrameExtractor\n",
    "from modules.octa_video_util import buildImageDataset, buildImageDatasetThreads\n",
    "from modules.octa_video_util import copy_images_to_folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdc9d06-255e-45b9-8eb5-cfecdcf0db3e",
   "metadata": {},
   "source": [
    "#### Download videos with optional query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ec12290-7965-4fae-a826-2639bd245ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE! 14679/14679 files downloaded.0%)\n"
     ]
    }
   ],
   "source": [
    "# from modules.octa_video_util import VideoDownloader\n",
    "\n",
    "target_directory = 'data/videos'\n",
    "bucket_name = 'flood-video-collection'\n",
    "\n",
    "# query_params = {'code': [101, 102, 103], 'seen': [True, False]} \n",
    "query_params = {'seen': [True]}\n",
    "\n",
    "overwrite = False\n",
    "max_threads = 12\n",
    "\n",
    "# Exclude missing video manually\n",
    "df_custom_2 = df_custom[~df_custom['blob_name'].str.contains('parallel')]\n",
    "\n",
    "downloader = VideoDownloader(df_custom_2, target_directory, google_credentials_path, max_threads)\n",
    "downloader.download_videos(query_params, overwrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581a7802-4e30-43d8-a894-ed5aedb010f5",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Build images dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6201bcc7-f212-4501-b2ae-5460702813ec",
   "metadata": {},
   "source": [
    "Create the dataset of images from the video files in `base_directory` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb542d3-7414-4328-9d16-0db41df79487",
   "metadata": {},
   "source": [
    "Obs: To update to the latest 'tags' and 'seen' values, re-download the 'videos' dataset and pass it down to `buildImageDataset` or `buildImageDatasetThreads` below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b69c08-ca46-479b-b7cf-03d701f58691",
   "metadata": {},
   "source": [
    "#### Build images dataset from video files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3528ccc-4015-476b-a205-10b0f3686f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed videos: 14679/14679 (100.0) %\n",
      "\n",
      "Image dataset shape: (591919, 10)\n"
     ]
    }
   ],
   "source": [
    "from modules.octa_video_util import buildImageDataset\n",
    "from modules.octa_video_util import _assign_tag\n",
    "\n",
    "dataset = df_custom_2.copy()\n",
    "base_directory = 'data/videos'\n",
    "images_dataset_path = 'data/datasets/images.csv'\n",
    "fps = 3\n",
    "\n",
    "# Build images dataset\n",
    "df_images =  buildImageDataset(dataset, base_directory, fps=fps)\n",
    "\n",
    "# Save images dataset\n",
    "df_images.to_csv(images_dataset_path, index=False)\n",
    "\n",
    "# Print results\n",
    "print('Image dataset shape:', df_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735d2479-6fad-422b-a227-639fecf78639",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Extract and save image files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f260c0-7ca4-4225-b2b3-17f4ced11bfb",
   "metadata": {},
   "source": [
    "#### Extract images from video files (with optional query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34244ea9-66fb-4f39-87a0-31f707e13bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 14679/14679 rows (100.00%)\n",
      "\n",
      "FINISHED.\n",
      "\n",
      "Frames found: 591919\n",
      "Frames written to disk: 591919\n",
      "Frames folder exists: 0\n",
      "Videos not found: 0\n"
     ]
    }
   ],
   "source": [
    "# from modules.octa_video_util import VideoFrameExtractor\n",
    "# from modules.octa_video_util import filter_by_query\n",
    "\n",
    "base_directory = 'data/videos'\n",
    "target_directory = 'data/images'\n",
    "query_params = { 'seen': [True] }\n",
    "MAX_THREADS = 10  # BE CAREFUL WITH `max_threads`\n",
    "overwrite = False\n",
    "fps = 3\n",
    "delete_on_success = True \n",
    "\n",
    "df_custom_2 = df_custom[~df_custom['blob_name'].str.contains('parallel')]\n",
    "\n",
    "df_filtered = filter_by_query(df_custom_2, query_params).copy()\n",
    "frame_extractor = VideoFrameExtractor(df_filtered, base_directory, target_directory, MAX_THREADS)\n",
    "frame_extractor.extract_frames(overwrite, fps, delete_on_success)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc70e9a-5f15-450c-97d6-635b705edb3d",
   "metadata": {},
   "source": [
    "#### Count saved images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27a3c749-e1ee-4959-944c-e404c8636dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of '.jpg' files in 'data/images': 591919\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "def count_files_with_extension(folder_path, ext=\"\"):\n",
    "    count = 0\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith(ext):\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "# Example usage:\n",
    "folder_path = \"data/images\"\n",
    "extension = \".jpg\"\n",
    "file_count = count_files_with_extension(folder_path, extension)\n",
    "print(f\"Number of '{extension}' files in '{folder_path}': {file_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1acfbc-e3da-4b72-94c7-e939520cec3c",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Reload images dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dd947e5-a58c-4146-95df-da4445c2cc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "images_dataset_path = 'data/datasets/images.csv'\n",
    "df_images = pd.read_csv(images_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598a893c-8942-4d26-b4c7-fe816b96699e",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Preprocess the images dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54d2ff9-c800-4a4f-88c0-1cf2ff3464d5",
   "metadata": {},
   "source": [
    "Add useful and convenient information as new fields of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0be01982-73f8-45d5-9c48-18e44bb193fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.octa_video_util import _assign_tag\n",
    "from modules.octa_video_util import filter_by_query\n",
    "\n",
    "df_images_clean = df_images.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1289acdf-759c-4231-84cf-e7a6ca23697c",
   "metadata": {},
   "source": [
    "#### Create field `tag` based on tag priority list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "428a75cf-5e15-4f7e-a94d-dac07eba5d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag\n",
       "normal        461519\n",
       "bolsão         49619\n",
       "alagamento     42560\n",
       "lâmina         38221\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "default_tag = 'normal'\n",
    "tags_priority_list = ['alagamento', 'bolsão', 'lâmina']\n",
    "\n",
    "# Create unique tag column based on class priority list\n",
    "df_images_clean['tag'] = df_images_clean['tags'].apply(lambda tags_list: _assign_tag(tags_list, tags_priority_list, default_tag))\n",
    "\n",
    "display(df_images_clean.tag.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a078c02-b815-4180-ba4d-25ddf676d082",
   "metadata": {},
   "source": [
    "#### Create `flood` field (binarize tag field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3aa040b8-f3f5-4ac0-9b86-e99ac9188f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flood\n",
       "0    461519\n",
       "1    130400\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=10, step=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_classes = ['lâmina', 'bolsão', 'alagamento']\n",
    "\n",
    "# Binarize categorical variable from list of target classes\n",
    "df_images_clean['flood'] = df_images_clean['tag'].isin(target_classes).astype(int)\n",
    "\n",
    "display(df_images_clean['flood'].value_counts())\n",
    "print()\n",
    "display(df_images_clean.index[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf5a347-901c-4170-b3da-d5c46de74bd9",
   "metadata": {},
   "source": [
    "#### Save processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cf6c020-552c-4c69-a55f-63fa05c8faf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Images Dataset Saved at: 2024-03-08 02:01:40.863189\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "df_images_clean.to_csv('data/datasets/images_clean.csv', index=False)\n",
    "\n",
    "print('Clean Images Dataset Saved at:', str(datetime.now()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
