{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b64e293-c7bb-43c6-90e3-bef3c6a1a45a",
   "metadata": {},
   "source": [
    "#### Reload images and videos datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4829e75-ae85-4e3e-b477-1dfb348428d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['_id', 'blob_name', 'blob_size', 'bucket_name', 'file_name', 'code',\n",
      "       'n_folders', 'timestamp', 'folder_structure', 'folder', 'tags', 'url',\n",
      "       'api_url', 'bucket', 'seen'],\n",
      "      dtype='object')\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=10, step=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "df_images = pd.read_csv('data/datasets-full/images_clean.csv')\n",
    "df_videos = pd.read_csv('data/datasets-full/videos.csv')\n",
    "\n",
    "df_videos['tags'] = df_videos['tags'].apply(json.loads)\n",
    "\n",
    "print(df_videos.columns)\n",
    "print()\n",
    "display(df_videos.index[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061157ec-915a-4791-9834-4c2fb19aa9b7",
   "metadata": {},
   "source": [
    "#### Check existence of images in folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9902a963-c2c1-45dc-8981-ccec0a3fd907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'100.0 %'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "def get_nested_files(folder_path):\n",
    "    file_paths = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            file_paths.append(file_path.replace('\\\\', '/'))\n",
    "    return file_paths\n",
    "\n",
    "\n",
    "base_path = 'data/images'\n",
    "images_paths_found = get_nested_files(base_path)\n",
    "\n",
    "images_paths_sample = df_images['file_path'].apply(lambda file_path: f'{base_path}/{file_path}'.replace('\\\\', '/'))\n",
    "files_exist_prct = images_paths_sample.isin(images_paths_found).mean()\n",
    "\n",
    "print('Files found:', round(files_exist_prct * 100, 2) + ' %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cf8e85-147f-4e15-a8ae-1aedf867e8e4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf0b98e-17fe-4b09-811e-e1eb7372cd32",
   "metadata": {},
   "source": [
    "## Run predictions with YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0badd0-aae0-4a72-86ec-b6e23ca7447a",
   "metadata": {},
   "source": [
    "#### Load model with Yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a5d8675-1d5f-424d-abec-0b109649a8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Path to the folder you want to zip\n",
    "# model_path = f'models/sgkf-8-1-1/weights/best.pt'\n",
    "# model_path = f'models/sgkf-50-25-25-size-2024-rs-2/weights/best.pt'\n",
    "model_path = f'models/full-imbalanced-train/weights/best.pt'\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(model_path)  # load a partially trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa93b7db-727c-44e9-b732-a2e840cc9cca",
   "metadata": {},
   "source": [
    "#### Compare time to predict using batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa749b5-3257-4e08-bf2a-9e4033bba260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "path_field = 'full_file_path'\n",
    "\n",
    "df_images[path_field] = f'{base_path}/' + df_images['file_path']\n",
    "\n",
    "n = 15\n",
    "batch = 16\n",
    "batch_paths = df_images[path_field].iloc[:batch].tolist()\n",
    "\n",
    "s = time.time()\n",
    "for i in range(n):\n",
    "    for img_path in batch_paths:\n",
    "        model.predict(img_path, verbose=False)\n",
    "    diff = time.time() - s\n",
    "    avg = round(diff / n, 3)\n",
    "\n",
    "print('Avg-Time Op. 1: ', avg, 's')\n",
    "\n",
    "s = time.time()\n",
    "for i in range(n):\n",
    "    model.predict(batch_paths, batch=1, verbose=False)\n",
    "    diff = time.time() - s\n",
    "    avg = round(diff / n, 3)\n",
    "\n",
    "print('Avg-Time Op. 2: ', avg, 's')\n",
    "\n",
    "s = time.time()\n",
    "for i in range(n):\n",
    "    model.predict(batch_paths, batch=batch, verbose=False)\n",
    "    diff = time.time() - s\n",
    "    avg = round(diff / n, 3)\n",
    "\n",
    "print('Avg-Time Op. 3: ', avg, 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3307f52a-505b-46e0-a938-84ea31e61636",
   "metadata": {},
   "source": [
    "#### Run predictions with yolo in batch progressively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d95d85f-5183-4fc4-9697-0f6a10a1b4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Interrupted | image-results-saved: 240 / 2330639 | time-running: 0.37 min / 7960.41 min | time-left: 7959.59 min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([[541984.0, nan, nan],\n",
       "  [541985.0, nan, nan],\n",
       "  [541986.0, nan, nan],\n",
       "  [541987.0, nan, nan],\n",
       "  [541988.0, nan, nan],\n",
       "  [542660.0, nan, nan],\n",
       "  [542661.0, nan, nan],\n",
       "  [542662.0, nan, nan],\n",
       "  [542663.0, nan, nan],\n",
       "  [542664.0, nan, nan]],\n",
       " 'Size: 240')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from IPython.display import clear_output as co\n",
    "import traceback\n",
    "\n",
    "def yolo_classify_dataset_batches(\n",
    "    model, df, path_field,\n",
    "    batch=8, save_each=10, save_path=None, save_error=True,\n",
    "    predict_args={'imgsz': 640, 'device': 'cpu'},\n",
    "):\n",
    "    index_start = 0\n",
    "    preds = []\n",
    "    errors = []\n",
    "\n",
    "    if save_path is not None:\n",
    "        pred_path = f'{save_path}/images_pred.csv'\n",
    "        error_path = f'{save_path}/errors.json'\n",
    "\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "\n",
    "        if os.path.exists(pred_path):\n",
    "            preds_df = pd.read_csv(pred_path)\n",
    "            index_start = len(preds_df)\n",
    "            preds = preds_df.values.tolist()\n",
    "\n",
    "        if save_error and os.path.exists(error_path):\n",
    "            errors = json.load(open(error_path, 'r'))\n",
    "\n",
    "    sources = df[path_field]  # .iloc[index_start:]\n",
    "    n_imgs = len(sources)\n",
    "    s_time = time.time()\n",
    "    \n",
    "    for i in range(index_start, n_imgs, batch):\n",
    "\n",
    "        e_time = time.time() - s_time\n",
    "        e_time_round = round(e_time / 60, 2)\n",
    "        avg_time = e_time / max(1, i - index_start)\n",
    "        expected_finish_time = round((n_imgs - i) * avg_time / 60, 2)\n",
    "        expected_total_time = round((n_imgs - index_start) * avg_time  / 60, 2)\n",
    "    \n",
    "        co(True)\n",
    "        print(f'image-results-saved: {i} / {n_imgs} | time-running: {e_time_round} min / {expected_total_time} min | time-left: {expected_finish_time} min')    \n",
    "    \n",
    "        batch_index = int(i / batch)\n",
    "        sources_batch = sources[i: i + batch]\n",
    "        \n",
    "        try:\n",
    "            pred = model.predict(sources_batch.tolist(), **predict_args)\n",
    "            pred = [[idx, pred_i.probs.data[1].item(), pred_i.probs.top1] for idx, pred_i in zip(sources_batch.index, pred)]\n",
    "            preds.extend(pred)\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            co(True)\n",
    "            print(f'Process Interrupted | image-results-saved: {i} / {n_imgs} | time-running: {e_time_round} min / {expected_total_time} min | time-left: {expected_finish_time} min')    \n",
    "            return preds\n",
    "        \n",
    "        except Exception as e:\n",
    "            traceback_str = traceback.format_exc()\n",
    "            errors.append({'index_start': i, 'index_end': i + batch - 1, 'batch_index': batch_index, 'error': str(e), 'traceback': traceback_str})\n",
    "                            \n",
    "            pred = [[idx, None, None] for idx in sources_batch.index]\n",
    "            preds.extend(pred)\n",
    "        \n",
    "        if save_path is not None:\n",
    "            if batch_index % save_each == 0: # NOTE: MISSING SAVING THE LAST BATCH\n",
    "                pd.DataFrame(preds, columns=['index', 'prob', 'pred']).to_csv(pred_path, index=False)\n",
    "                \n",
    "                if save_path is not None and save_error:\n",
    "                    with open(error_path, 'w') as fw:\n",
    "                        fw.write(json.dumps(errors))\n",
    "                # print(f'Results saved | IMAGES: {i + batch} / {n_imgs} | BATCH: {batch_index} | PATH: {save_path}')\n",
    "    \n",
    "    co(True)\n",
    "    print(f'image-results-saved: {i + batch} / {n_imgs} | time-running: {e_time_round} min / {expected_total_time} min | time-left: {expected_finish_time} min')\n",
    "    \n",
    "    if save_path is not None:\n",
    "        print(f'\\nDataset with results saved to: {save_path}')\n",
    "    \n",
    "    return preds\n",
    "\n",
    "\n",
    "# ---\n",
    "\n",
    "base_path = 'data/images'\n",
    "\n",
    "df_images['full_file_path'] = f'{base_path}/' + df_images['file_path']\n",
    "\n",
    "df = df_images.sort_values(['code', 'initial_timestamp', 'id_video', 'frame_index'])\n",
    "path_field = 'full_file_path'\n",
    "batch = 12\n",
    "save_each = 100\n",
    "save_path = 'data/datasets/images_pred'\n",
    "save_error = True\n",
    "predict_args = {'imgsz': 640, 'device': 'cpu', 'verbose': False}\n",
    "\n",
    "preds = yolo_classify_dataset_batches(model, df, path_field, batch, save_each, save_path, save_error, predict_args)\n",
    "\n",
    "preds[:10], f'Size: {len(preds)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6cb429-6d96-477d-bb77-72c5667e5bb0",
   "metadata": {},
   "source": [
    "#### Convert image labels to video labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32f6b4e8-5fc5-4733-87d7-4b0e4d71c0c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>blob_name</th>\n",
       "      <th>prob_mean</th>\n",
       "      <th>prob_std</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>65040934f049f672e58adc46</td>\n",
       "      <td>comando/alagamento/93901/1026/CODE1026 2023-03...</td>\n",
       "      <td>9.371731e-04</td>\n",
       "      <td>1.059198e-04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65040934f049f672e58adc47</td>\n",
       "      <td>comando/alagamento/93901/1026/CODE1026 2023-03...</td>\n",
       "      <td>9.260222e-04</td>\n",
       "      <td>1.356357e-04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>65040934f049f672e58adc48</td>\n",
       "      <td>comando/alagamento/93901/1026/CODE1026 2023-03...</td>\n",
       "      <td>2.225615e-09</td>\n",
       "      <td>2.815121e-09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>65040934f049f672e58adc49</td>\n",
       "      <td>comando/alagamento/93901/1026/CODE1026 2023-03...</td>\n",
       "      <td>1.630687e-07</td>\n",
       "      <td>8.887154e-07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>65040934f049f672e58adc4a</td>\n",
       "      <td>comando/alagamento/93901/1026/CODE1026 2023-03...</td>\n",
       "      <td>8.380167e-09</td>\n",
       "      <td>1.136922e-08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          _id  \\\n",
       "89   65040934f049f672e58adc46   \n",
       "2    65040934f049f672e58adc47   \n",
       "90   65040934f049f672e58adc48   \n",
       "200  65040934f049f672e58adc49   \n",
       "91   65040934f049f672e58adc4a   \n",
       "\n",
       "                                             blob_name     prob_mean  \\\n",
       "89   comando/alagamento/93901/1026/CODE1026 2023-03...  9.371731e-04   \n",
       "2    comando/alagamento/93901/1026/CODE1026 2023-03...  9.260222e-04   \n",
       "90   comando/alagamento/93901/1026/CODE1026 2023-03...  2.225615e-09   \n",
       "200  comando/alagamento/93901/1026/CODE1026 2023-03...  1.630687e-07   \n",
       "91   comando/alagamento/93901/1026/CODE1026 2023-03...  8.380167e-09   \n",
       "\n",
       "         prob_std  pred  \n",
       "89   1.059198e-04   0.0  \n",
       "2    1.356357e-04   0.0  \n",
       "90   2.815121e-09   0.0  \n",
       "200  8.887154e-07   0.0  \n",
       "91   1.136922e-08   0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (24555, 5)\n",
      "\n",
      "pred\n",
      "0.0    22852\n",
      "1.0     1577\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "preds_path = 'data/datasets-full/images_pred/images_pred.csv'\n",
    "\n",
    "preds = pd.read_csv(preds_path)\n",
    "\n",
    "preds_new = preds.copy()\n",
    "\n",
    "df_images_predicted = df_images.loc[preds['index']]\n",
    "\n",
    "df_images_predicted[['prob', 'pred']] = preds[['prob', 'pred']].values\n",
    "\n",
    "video_prob_stats = df_images_predicted.groupby(['id_video'])['prob'].agg(['mean', 'std'])\n",
    "video_prob_stats.columns = ['prob_mean', 'prob_std']\n",
    "video_pred = df_images_predicted.groupby(['id_video'])['pred'].max()\n",
    "\n",
    "videos_predicted = pd.concat([video_prob_stats, video_pred], axis=1)\n",
    "\n",
    "# Merge additional video data\n",
    "videos_predicted = df_videos[['_id', 'blob_name']].join(videos_predicted, on='_id', how='right')\n",
    "\n",
    "display(videos_predicted.head())\n",
    "\n",
    "print('Shape:', videos_predicted.shape)\n",
    "print()\n",
    "print(videos_predicted['pred'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37d50ecd-aff0-432f-90d8-f4d9ff94c40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>blob_name</th>\n",
       "      <th>prob_mean</th>\n",
       "      <th>prob_std</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>65040934f049f672e58adc46</td>\n",
       "      <td>comando/alagamento/93901/1026/CODE1026 2023-03...</td>\n",
       "      <td>9.371731e-04</td>\n",
       "      <td>1.059198e-04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65040934f049f672e58adc47</td>\n",
       "      <td>comando/alagamento/93901/1026/CODE1026 2023-03...</td>\n",
       "      <td>9.260222e-04</td>\n",
       "      <td>1.356357e-04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>65040934f049f672e58adc48</td>\n",
       "      <td>comando/alagamento/93901/1026/CODE1026 2023-03...</td>\n",
       "      <td>2.225615e-09</td>\n",
       "      <td>2.815121e-09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>65040934f049f672e58adc49</td>\n",
       "      <td>comando/alagamento/93901/1026/CODE1026 2023-03...</td>\n",
       "      <td>1.630687e-07</td>\n",
       "      <td>8.887154e-07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>65040934f049f672e58adc4a</td>\n",
       "      <td>comando/alagamento/93901/1026/CODE1026 2023-03...</td>\n",
       "      <td>8.380167e-09</td>\n",
       "      <td>1.136922e-08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          _id  \\\n",
       "89   65040934f049f672e58adc46   \n",
       "2    65040934f049f672e58adc47   \n",
       "90   65040934f049f672e58adc48   \n",
       "200  65040934f049f672e58adc49   \n",
       "91   65040934f049f672e58adc4a   \n",
       "\n",
       "                                             blob_name     prob_mean  \\\n",
       "89   comando/alagamento/93901/1026/CODE1026 2023-03...  9.371731e-04   \n",
       "2    comando/alagamento/93901/1026/CODE1026 2023-03...  9.260222e-04   \n",
       "90   comando/alagamento/93901/1026/CODE1026 2023-03...  2.225615e-09   \n",
       "200  comando/alagamento/93901/1026/CODE1026 2023-03...  1.630687e-07   \n",
       "91   comando/alagamento/93901/1026/CODE1026 2023-03...  8.380167e-09   \n",
       "\n",
       "         prob_std  pred  \n",
       "89   1.059198e-04   0.0  \n",
       "2    1.356357e-04   0.0  \n",
       "90   2.815121e-09   0.0  \n",
       "200  8.887154e-07   0.0  \n",
       "91   1.136922e-08   0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (20751, 5)\n",
      "\n",
      "pred\n",
      "0.0    19149\n",
      "1.0     1489\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "preds_path = 'data/datasets-full/images_pred/images_pred_old.csv'\n",
    "\n",
    "preds = pd.read_csv(preds_path)\n",
    "\n",
    "df_images_predicted = df_images.loc[preds['index']]\n",
    "\n",
    "df_images_predicted[['prob', 'pred']] = preds[['prob', 'pred']].values\n",
    "\n",
    "video_prob_stats = df_images_predicted.groupby(['id_video'])['prob'].agg(['mean', 'std'])\n",
    "video_prob_stats.columns = ['prob_mean', 'prob_std']\n",
    "video_pred = df_images_predicted.groupby(['id_video'])['pred'].max()\n",
    "\n",
    "videos_predicted = pd.concat([video_prob_stats, video_pred], axis=1)\n",
    "\n",
    "# Merge additional video data\n",
    "videos_predicted = df_videos[['_id', 'blob_name']].join(videos_predicted, on='_id', how='right')\n",
    "\n",
    "display(videos_predicted.head())\n",
    "\n",
    "print('Shape:', videos_predicted.shape)\n",
    "print()\n",
    "print(videos_predicted['pred'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a448d9a8-ae7b-4f15-9568-3f35d6fb1e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((756816, 3), (878191, 3))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape, preds_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e926b376-4ead-48a9-957e-7d0d1e970d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index       0\n",
       "prob     4768\n",
       "pred     4768\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "831ca44e-8f9d-47f2-885f-1571e4c7a995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index       0\n",
       "prob     5409\n",
       "pred     5409\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_new.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5341b95-e89a-4200-b9e4-a01d8e89ac58",
   "metadata": {},
   "source": [
    "#### Analyze errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ef6c6bf1-5c01-4c77-bd68-6cffa112f034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_start</th>\n",
       "      <th>index_end</th>\n",
       "      <th>batch_index</th>\n",
       "      <th>error</th>\n",
       "      <th>traceback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56672</td>\n",
       "      <td>56687</td>\n",
       "      <td>3542</td>\n",
       "      <td>cannot identify image file 'data/images/polygo...</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"C:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56688</td>\n",
       "      <td>56703</td>\n",
       "      <td>3543</td>\n",
       "      <td>cannot identify image file 'data/images/polygo...</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"C:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56704</td>\n",
       "      <td>56719</td>\n",
       "      <td>3544</td>\n",
       "      <td>cannot identify image file 'data/images/polygo...</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"C:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57584</td>\n",
       "      <td>57599</td>\n",
       "      <td>3599</td>\n",
       "      <td>cannot identify image file 'data/images/polygo...</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"C:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57600</td>\n",
       "      <td>57615</td>\n",
       "      <td>3600</td>\n",
       "      <td>cannot identify image file 'data/images/polygo...</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"C:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index_start  index_end  batch_index  \\\n",
       "0        56672      56687         3542   \n",
       "1        56688      56703         3543   \n",
       "2        56704      56719         3544   \n",
       "3        57584      57599         3599   \n",
       "4        57600      57615         3600   \n",
       "\n",
       "                                               error  \\\n",
       "0  cannot identify image file 'data/images/polygo...   \n",
       "1  cannot identify image file 'data/images/polygo...   \n",
       "2  cannot identify image file 'data/images/polygo...   \n",
       "3  cannot identify image file 'data/images/polygo...   \n",
       "4  cannot identify image file 'data/images/polygo...   \n",
       "\n",
       "                                           traceback  \n",
       "0  Traceback (most recent call last):\\n  File \"C:...  \n",
       "1  Traceback (most recent call last):\\n  File \"C:...  \n",
       "2  Traceback (most recent call last):\\n  File \"C:...  \n",
       "3  Traceback (most recent call last):\\n  File \"C:...  \n",
       "4  Traceback (most recent call last):\\n  File \"C:...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (593, 5) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "errors_path = 'data/datasets-full/images_pred/errors.json'\n",
    "\n",
    "errors = pd.DataFrame(json.load(open(errors_path, 'r')))\n",
    "\n",
    "display(errors.head())\n",
    "print('Shape:', errors.shape, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74710835-b4c1-41bf-b760-32d577e0fdda",
   "metadata": {},
   "source": [
    "#### Post video classification results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d83cc3-4b35-4f43-82d4-ee82d29bb9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from IPython.display import clear_output as co\n",
    "\n",
    "bucket = 'flood-videos-stamped'\n",
    "progress_path = 'data/datasets-full/images_pred_post/progress.json'\n",
    "error_path = 'data/datasets-full/images_pred_post/errors.json'\n",
    "save_each = 100\n",
    "id_field = '_id'\n",
    "df = videos_predicted[videos_predicted['pred'] == 1].copy()\n",
    "\n",
    "base_url = 'https://watch-bucket-veuei2iu4q-uc.a.run.app'\n",
    "# base_url = 'http://localhost:8080'\n",
    "video_tags = VideoTags(base_url)\n",
    "\n",
    "progress = {idx: False for idx in df['_id']}\n",
    "if os.path.exists(progress_path):\n",
    "    progress_saved = json.load(open(progress_path, 'r'))\n",
    "    progress = {**progress, **progress_saved}\n",
    "    \n",
    "\n",
    "done = sum(list(progress.values()))\n",
    "done_start = done\n",
    "\n",
    "errors = []\n",
    "if os.path.exists(error_path):\n",
    "    errors = json.load(open(error_path, 'r'))\n",
    "\n",
    "n_videos = len(df)\n",
    "s_time = time.time()\n",
    "\n",
    "for i, (idx, row) in enumerate(df.iterrows()):\n",
    "    \n",
    "    e_time = time.time() - s_time\n",
    "    e_time_round = round(e_time / 60, 2)\n",
    "    avg_time = e_time / max(1, i - done_start)\n",
    "    expected_finish_time = round((n_videos - i) * avg_time / 60, 2)\n",
    "    expected_total_time = round(n_videos * avg_time  / 60, 2)\n",
    "\n",
    "    co(True)\n",
    "    print(f'PROCESSED: {i} / {n_videos} | POSTED: {done} / {n_videos} | TIME-RUNNING: {e_time_round} min / {expected_total_time} min | TIME-LEFT: {expected_finish_time} min | ERRORS: {len(errors)}')    \n",
    "\n",
    "    id_video = row['_id']\n",
    "    blob_name = row['blob_name']\n",
    "    prob_mean = row['prob_mean']\n",
    "    prob_std = row['prob_std']\n",
    "    pred = row['pred']\n",
    "\n",
    "    tags = ['acúmulo-ia' if pred is not None and pred else 'normal-ia']\n",
    "\n",
    "    if not progress[id_video]:\n",
    "        data = video_tags.post(tags, blob_name, bucket)\n",
    "        \n",
    "        success = data['status'] and data['data'] is not None and 'message' in data['data'] and 'successfully' in data['data']['message']\n",
    "        \n",
    "        if success:\n",
    "            progress[id_video] = True\n",
    "            done += 1\n",
    "        \n",
    "        else:\n",
    "            errors.append({'id_video': id_video, **data})\n",
    "            \n",
    "    if (i + 1) % save_each == 0 or (i + 1) == n_videos:\n",
    "        with open(progress_path, 'w') as fw:\n",
    "            fw.write(json.dumps(progress))\n",
    "            \n",
    "        with open(error_path, 'w') as fw:\n",
    "            fw.write(json.dumps(errors))\n",
    "\n",
    "    co(True)\n",
    "    print(f'PROCESSED: {i + 1} / {n_videos} | POSTED: {done} / {n_videos} | TIME-RUNNING: {e_time_round} min / {expected_total_time} min | TIME-LEFT: {expected_finish_time} min | ERRORS: {len(errors)}')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c0a6d3-d66a-44f7-ac97-673857a79371",
   "metadata": {},
   "source": [
    "---\n",
    "## Manage video tags with mongo based api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8562f300-dd95-4e69-bcb1-5b39e8f0a68b",
   "metadata": {},
   "source": [
    "#### Class to handle tags for videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cb39981-157d-43d9-bafe-a902ebf72b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "class VideoTags:\n",
    "    def __init__(self, base_url):\n",
    "        self.base_url = base_url\n",
    "        \n",
    "    #### Get tags\n",
    "    def get(self, blob_name, bucket):\n",
    "        url = f'{self.base_url}/tags/{blob_name}?b={bucket}'\n",
    "        res = requests.get(url)\n",
    "        if not res.ok:\n",
    "            data = None\n",
    "        else: data = res.json()\n",
    "        return {'status': res.ok, 'status_code': res.status_code, 'message': res.reason, 'data': data}\n",
    "    \n",
    "    #### Post tags\n",
    "    def post(self, tags, blob_name, bucket):\n",
    "        url_tags = f'{self.base_url}/tags';\n",
    "        data = {\n",
    "            'tags': tags,\n",
    "            'b': bucket,\n",
    "            'blob_name': blob_name,\n",
    "        };\n",
    "        res = requests.post(url_tags, json=data)\n",
    "        if not res.ok:\n",
    "            data = None\n",
    "        else: data = res.json()\n",
    "        return {'status': res.ok, 'status_code': res.status_code, 'message': res.reason, 'data': data}\n",
    "    \n",
    "    #### Delete tag\n",
    "    def delete(self, tag, blob_name, bucket):\n",
    "        url = f'{self.base_url}/tags/{tag}?blob_name={blob_name}&b={bucket}'\n",
    "        res = requests.delete(url)\n",
    "        if not res.ok:\n",
    "            data = None\n",
    "        else: data = res.json()\n",
    "        return {'status': res.ok, 'status_code': res.status_code, 'message': res.reason, 'data': data}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cf8ff3-62ef-49b3-a9bd-3490aa0c767f",
   "metadata": {},
   "source": [
    "#### Create VideoTags instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bae416ed-ea2d-4824-8340-3519b85a7242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_url = 'https://watch-bucket-veuei2iu4q-uc.a.run.app'\n",
    "base_url = 'http://localhost:8080'\n",
    "video_tags = VideoTags(base_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412fb9d7-6087-4c3d-b839-11981a667e08",
   "metadata": {},
   "source": [
    "#### Define video parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e6cef3d-ae6e-47b7-b183-6ae8a7c06d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'flood-videos-stamped'\n",
    "blob_name = 'comando/alagamento/101579/1461/CODE1461 2023-08-29 00-00-02.webm'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8865d0-4e7b-4977-8b74-147225943624",
   "metadata": {},
   "source": [
    "#### Get tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "28c631ed-72a8-4472-8078-242b8d96c131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': True,\n",
       " 'status_code': 200,\n",
       " 'message': 'OK',\n",
       " 'data': {'_id': '65040934f049f672e58adc41',\n",
       "  'api_url': 'https://watch-bucket-j3velvy4eq-rj.a.run.app/ffmpeg/comando/alagamento/101579/1461/CODE1461 2023-08-29 00-00-02.webm?b=flood-videos-stamped',\n",
       "  'blob_name': 'comando/alagamento/101579/1461/CODE1461 2023-08-29 00-00-02.webm',\n",
       "  'blob_size': 2047337.0,\n",
       "  'bucket': '',\n",
       "  'bucket_name': 'flood-videos-stamped',\n",
       "  'code': 1461.0,\n",
       "  'file_name': 'CODE1461 2023-08-29 00-00-02.webm',\n",
       "  'folder': 'comando/alagamento/101579/1461',\n",
       "  'folder_structure': '{source}/{type}/{event}/{code}',\n",
       "  'n_folders': 4.0,\n",
       "  'seen': True,\n",
       "  'tags': ['poça'],\n",
       "  'timestamp': '2023-08-29 00:00:02',\n",
       "  'url': 'https://storage.googleapis.com/flood-videos-stamped/comando/alagamento/101579/1461/CODE1461 2023-08-29 00-00-02.webm'}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_tags.get(blob_name, bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62079ae5-d4a4-429d-82f6-ea554b0160ab",
   "metadata": {},
   "source": [
    "#### Post tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c46239a-f6ee-47c5-9071-ae95735da805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': True,\n",
       " 'status_code': 200,\n",
       " 'message': 'OK',\n",
       " 'data': {'message': 'Tags updated successfully'}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = ['acúmulo-ia']\n",
    "\n",
    "video_tags.post(tags, blob_name, bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80f95fd-1f08-49f0-a584-b1b73212285e",
   "metadata": {},
   "source": [
    "#### Delete tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f45689e5-4a65-4f92-93f8-92005c390c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': True,\n",
       " 'status_code': 200,\n",
       " 'message': 'OK',\n",
       " 'data': {'_id': '65040934f049f672e58adc41',\n",
       "  'api_url': 'https://watch-bucket-j3velvy4eq-rj.a.run.app/ffmpeg/comando/alagamento/101579/1461/CODE1461 2023-08-29 00-00-02.webm?b=flood-videos-stamped',\n",
       "  'blob_name': 'comando/alagamento/101579/1461/CODE1461 2023-08-29 00-00-02.webm',\n",
       "  'blob_size': 2047337.0,\n",
       "  'bucket': '',\n",
       "  'bucket_name': 'flood-videos-stamped',\n",
       "  'code': 1461.0,\n",
       "  'file_name': 'CODE1461 2023-08-29 00-00-02.webm',\n",
       "  'folder': 'comando/alagamento/101579/1461',\n",
       "  'folder_structure': '{source}/{type}/{event}/{code}',\n",
       "  'n_folders': 4.0,\n",
       "  'seen': True,\n",
       "  'tags': ['poça'],\n",
       "  'timestamp': '2023-08-29 00:00:02',\n",
       "  'url': 'https://storage.googleapis.com/flood-videos-stamped/comando/alagamento/101579/1461/CODE1461 2023-08-29 00-00-02.webm'}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag = 'acúmulo-ia'\n",
    "\n",
    "video_tags.delete(tag, blob_name, bucket)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
