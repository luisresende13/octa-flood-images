{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b64e293-c7bb-43c6-90e3-bef3c6a1a45a",
   "metadata": {},
   "source": [
    "#### Reload images and videos datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4829e75-ae85-4e3e-b477-1dfb348428d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['_id', 'blob_name', 'blob_size', 'bucket_name', 'file_name', 'code',\n",
      "       'n_folders', 'timestamp', 'folder_structure', 'folder', 'tags', 'url',\n",
      "       'api_url', 'bucket', 'seen'],\n",
      "      dtype='object')\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=10, step=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "df_images = pd.read_csv('data/datasets-full/images_clean.csv')\n",
    "df_videos = pd.read_csv('data/datasets-full/videos.csv')\n",
    "\n",
    "df_videos['tags'] = df_videos['tags'].apply(json.loads)\n",
    "\n",
    "print(df_videos.columns)\n",
    "print()\n",
    "display(df_videos.index[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061157ec-915a-4791-9834-4c2fb19aa9b7",
   "metadata": {},
   "source": [
    "#### Check existence of images in folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9902a963-c2c1-45dc-8981-ccec0a3fd907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'100.0 %'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "def get_nested_files(folder_path):\n",
    "    file_paths = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            file_paths.append(file_path.replace('\\\\', '/'))\n",
    "    return file_paths\n",
    "\n",
    "\n",
    "base_path = 'data/images'\n",
    "images_paths_found = get_nested_files(base_path)\n",
    "\n",
    "images_paths_sample = df_images['file_path'].apply(lambda file_path: f'{base_path}/{file_path}'.replace('\\\\', '/'))\n",
    "files_exist_prct = images_paths_sample.isin(images_paths_found).mean()\n",
    "\n",
    "print('Files found:', round(files_exist_prct * 100, 2) + ' %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cf8e85-147f-4e15-a8ae-1aedf867e8e4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf0b98e-17fe-4b09-811e-e1eb7372cd32",
   "metadata": {},
   "source": [
    "## Run predictions with YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0badd0-aae0-4a72-86ec-b6e23ca7447a",
   "metadata": {},
   "source": [
    "#### Load model with Yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a5d8675-1d5f-424d-abec-0b109649a8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Path to the folder you want to zip\n",
    "# model_path = f'models/sgkf-8-1-1/weights/best.pt'\n",
    "# model_path = f'models/sgkf-50-25-25-size-2024-rs-2/weights/best.pt'\n",
    "model_path = f'models/full-imbalanced-train/weights/best.pt'\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(model_path)  # load a partially trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa93b7db-727c-44e9-b732-a2e840cc9cca",
   "metadata": {},
   "source": [
    "#### Compare time to predict using batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa749b5-3257-4e08-bf2a-9e4033bba260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "path_field = 'full_file_path'\n",
    "\n",
    "df_images[path_field] = f'{base_path}/' + df_images['file_path']\n",
    "\n",
    "n = 15\n",
    "batch = 16\n",
    "batch_paths = df_images[path_field].iloc[:batch].tolist()\n",
    "\n",
    "s = time.time()\n",
    "for i in range(n):\n",
    "    for img_path in batch_paths:\n",
    "        model.predict(img_path, verbose=False)\n",
    "    diff = time.time() - s\n",
    "    avg = round(diff / n, 3)\n",
    "\n",
    "print('Avg-Time Op. 1: ', avg, 's')\n",
    "\n",
    "s = time.time()\n",
    "for i in range(n):\n",
    "    model.predict(batch_paths, batch=1, verbose=False)\n",
    "    diff = time.time() - s\n",
    "    avg = round(diff / n, 3)\n",
    "\n",
    "print('Avg-Time Op. 2: ', avg, 's')\n",
    "\n",
    "s = time.time()\n",
    "for i in range(n):\n",
    "    model.predict(batch_paths, batch=batch, verbose=False)\n",
    "    diff = time.time() - s\n",
    "    avg = round(diff / n, 3)\n",
    "\n",
    "print('Avg-Time Op. 3: ', avg, 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3307f52a-505b-46e0-a938-84ea31e61636",
   "metadata": {},
   "source": [
    "#### Run predictions with yolo in batch progressively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d95d85f-5183-4fc4-9697-0f6a10a1b4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Interrupted | image-results-saved: 240 / 2330639 | time-running: 0.37 min / 7960.41 min | time-left: 7959.59 min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([[541984.0, nan, nan],\n",
       "  [541985.0, nan, nan],\n",
       "  [541986.0, nan, nan],\n",
       "  [541987.0, nan, nan],\n",
       "  [541988.0, nan, nan],\n",
       "  [542660.0, nan, nan],\n",
       "  [542661.0, nan, nan],\n",
       "  [542662.0, nan, nan],\n",
       "  [542663.0, nan, nan],\n",
       "  [542664.0, nan, nan]],\n",
       " 'Size: 240')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from IPython.display import clear_output as co\n",
    "import traceback\n",
    "\n",
    "def yolo_classify_dataset_batches(\n",
    "    model, df, path_field,\n",
    "    batch=8, save_each=10, save_path=None, save_error=True,\n",
    "    predict_args={'imgsz': 640, 'device': 'cpu'},\n",
    "):\n",
    "    index_start = 0\n",
    "    preds = []\n",
    "    errors = []\n",
    "\n",
    "    if save_path is not None:\n",
    "        pred_path = f'{save_path}/images_pred.csv'\n",
    "        error_path = f'{save_path}/errors.json'\n",
    "\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "\n",
    "        if os.path.exists(pred_path):\n",
    "            preds_df = pd.read_csv(pred_path)\n",
    "            index_start = len(preds_df)\n",
    "            preds = preds_df.values.tolist()\n",
    "\n",
    "        if save_error and os.path.exists(error_path):\n",
    "            errors = json.load(open(error_path, 'r'))\n",
    "\n",
    "    sources = df[path_field]  # .iloc[index_start:]\n",
    "    n_imgs = len(sources)\n",
    "    s_time = time.time()\n",
    "    \n",
    "    for i in range(index_start, n_imgs, batch):\n",
    "\n",
    "        e_time = time.time() - s_time\n",
    "        e_time_round = round(e_time / 60, 2)\n",
    "        avg_time = e_time / max(1, i - index_start)\n",
    "        expected_finish_time = round((n_imgs - i) * avg_time / 60, 2)\n",
    "        expected_total_time = round((n_imgs - index_start) * avg_time  / 60, 2)\n",
    "    \n",
    "        co(True)\n",
    "        print(f'image-results-saved: {i} / {n_imgs} | time-running: {e_time_round} min / {expected_total_time} min | time-left: {expected_finish_time} min')    \n",
    "    \n",
    "        batch_index = int(i / batch)\n",
    "        sources_batch = sources[i: i + batch]\n",
    "        \n",
    "        try:\n",
    "            pred = model.predict(sources_batch.tolist(), **predict_args)\n",
    "            pred = [[idx, pred_i.probs.data[1].item(), pred_i.probs.top1] for idx, pred_i in zip(sources_batch.index, pred)]\n",
    "            preds.extend(pred)\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            co(True)\n",
    "            print(f'Process Interrupted | image-results-saved: {i} / {n_imgs} | time-running: {e_time_round} min / {expected_total_time} min | time-left: {expected_finish_time} min')    \n",
    "            return preds\n",
    "        \n",
    "        except Exception as e:\n",
    "            traceback_str = traceback.format_exc()\n",
    "            errors.append({'index_start': i, 'index_end': i + batch - 1, 'batch_index': batch_index, 'error': str(e), 'traceback': traceback_str})\n",
    "                            \n",
    "            pred = [[idx, None, None] for idx in sources_batch.index]\n",
    "            preds.extend(pred)\n",
    "        \n",
    "        if save_path is not None:\n",
    "            if batch_index % save_each == 0: # NOTE: MISSING SAVING THE LAST BATCH\n",
    "                pd.DataFrame(preds, columns=['index', 'prob', 'pred']).to_csv(pred_path, index=False)\n",
    "                \n",
    "                if save_path is not None and save_error:\n",
    "                    with open(error_path, 'w') as fw:\n",
    "                        fw.write(json.dumps(errors))\n",
    "                # print(f'Results saved | IMAGES: {i + batch} / {n_imgs} | BATCH: {batch_index} | PATH: {save_path}')\n",
    "    \n",
    "    co(True)\n",
    "    print(f'image-results-saved: {i + batch} / {n_imgs} | time-running: {e_time_round} min / {expected_total_time} min | time-left: {expected_finish_time} min')\n",
    "    \n",
    "    if save_path is not None:\n",
    "        print(f'\\nDataset with results saved to: {save_path}')\n",
    "    \n",
    "    return preds\n",
    "\n",
    "\n",
    "# ---\n",
    "\n",
    "base_path = 'data/images'\n",
    "\n",
    "df_images['full_file_path'] = f'{base_path}/' + df_images['file_path']\n",
    "\n",
    "df = df_images.sort_values(['code', 'initial_timestamp', 'id_video', 'frame_index'])\n",
    "path_field = 'full_file_path'\n",
    "batch = 12\n",
    "save_each = 100\n",
    "save_path = 'data/datasets/images_pred'\n",
    "save_error = True\n",
    "predict_args = {'imgsz': 640, 'device': 'cpu', 'verbose': False}\n",
    "\n",
    "preds = yolo_classify_dataset_batches(model, df, path_field, batch, save_each, save_path, save_error, predict_args)\n",
    "\n",
    "preds[:10], f'Size: {len(preds)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6cb429-6d96-477d-bb77-72c5667e5bb0",
   "metadata": {},
   "source": [
    "#### Convert image labels to video labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32f6b4e8-5fc5-4733-87d7-4b0e4d71c0c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>blob_name</th>\n",
       "      <th>prob_mean</th>\n",
       "      <th>prob_std</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>65040934f049f672e58adc3b</td>\n",
       "      <td>comando/alagamento/101579/1461/CODE1461 2023-0...</td>\n",
       "      <td>9.272117e-11</td>\n",
       "      <td>2.388217e-10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>65040934f049f672e58adc3c</td>\n",
       "      <td>comando/alagamento/101579/1461/CODE1461 2023-0...</td>\n",
       "      <td>1.495736e-11</td>\n",
       "      <td>2.246259e-11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>65040934f049f672e58adc3d</td>\n",
       "      <td>comando/alagamento/101579/1461/CODE1461 2023-0...</td>\n",
       "      <td>2.834461e-11</td>\n",
       "      <td>6.127894e-11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>65040934f049f672e58adc3e</td>\n",
       "      <td>comando/alagamento/101579/1461/CODE1461 2023-0...</td>\n",
       "      <td>8.243967e-13</td>\n",
       "      <td>1.995352e-12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>65040934f049f672e58adc3f</td>\n",
       "      <td>comando/alagamento/101579/1461/CODE1461 2023-0...</td>\n",
       "      <td>2.571478e-12</td>\n",
       "      <td>3.292951e-12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          _id  \\\n",
       "84   65040934f049f672e58adc3b   \n",
       "85   65040934f049f672e58adc3c   \n",
       "149  65040934f049f672e58adc3d   \n",
       "263  65040934f049f672e58adc3e   \n",
       "264  65040934f049f672e58adc3f   \n",
       "\n",
       "                                             blob_name     prob_mean  \\\n",
       "84   comando/alagamento/101579/1461/CODE1461 2023-0...  9.272117e-11   \n",
       "85   comando/alagamento/101579/1461/CODE1461 2023-0...  1.495736e-11   \n",
       "149  comando/alagamento/101579/1461/CODE1461 2023-0...  2.834461e-11   \n",
       "263  comando/alagamento/101579/1461/CODE1461 2023-0...  8.243967e-13   \n",
       "264  comando/alagamento/101579/1461/CODE1461 2023-0...  2.571478e-12   \n",
       "\n",
       "         prob_std  pred  \n",
       "84   2.388217e-10   0.0  \n",
       "85   2.246259e-11   0.0  \n",
       "149  6.127894e-11   0.0  \n",
       "263  1.995352e-12   0.0  \n",
       "264  3.292951e-12   0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (43113, 5)\n",
      "\n",
      "pred\n",
      "0.0    1539798\n",
      "1.0      59216\n",
      "Name: Images, dtype: int64\n",
      "\n",
      "pred\n",
      "0.0    40806\n",
      "1.0     2119\n",
      "Name: Videos, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "preds_path = 'data/datasets-full/images_pred/images_pred.csv'\n",
    "\n",
    "preds = pd.read_csv(preds_path)\n",
    "\n",
    "preds_new = preds.copy()\n",
    "\n",
    "df_images_predicted = df_images.loc[preds['index']]\n",
    "\n",
    "df_images_predicted[['prob', 'pred']] = preds[['prob', 'pred']].values\n",
    "\n",
    "video_prob_stats = df_images_predicted.groupby(['id_video'])['prob'].agg(['mean', 'std'])\n",
    "video_prob_stats.columns = ['prob_mean', 'prob_std']\n",
    "video_pred = df_images_predicted.groupby(['id_video'])['pred'].max()\n",
    "\n",
    "videos_predicted = pd.concat([video_prob_stats, video_pred], axis=1)\n",
    "\n",
    "# Merge additional video data\n",
    "videos_predicted = df_videos[['_id', 'blob_name']].join(videos_predicted, on='_id', how='right')\n",
    "\n",
    "display(videos_predicted.head())\n",
    "\n",
    "print('Shape:', videos_predicted.shape)\n",
    "print()\n",
    "print(preds['pred'].value_counts().rename('Images'))\n",
    "print()\n",
    "print(videos_predicted['pred'].value_counts().rename('Videos'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37d50ecd-aff0-432f-90d8-f4d9ff94c40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>blob_name</th>\n",
       "      <th>prob_mean</th>\n",
       "      <th>prob_std</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>65040934f049f672e58adc46</td>\n",
       "      <td>comando/alagamento/93901/1026/CODE1026 2023-03...</td>\n",
       "      <td>9.371731e-04</td>\n",
       "      <td>1.059198e-04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65040934f049f672e58adc47</td>\n",
       "      <td>comando/alagamento/93901/1026/CODE1026 2023-03...</td>\n",
       "      <td>9.260222e-04</td>\n",
       "      <td>1.356357e-04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>65040934f049f672e58adc48</td>\n",
       "      <td>comando/alagamento/93901/1026/CODE1026 2023-03...</td>\n",
       "      <td>2.225615e-09</td>\n",
       "      <td>2.815121e-09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>65040934f049f672e58adc49</td>\n",
       "      <td>comando/alagamento/93901/1026/CODE1026 2023-03...</td>\n",
       "      <td>1.630687e-07</td>\n",
       "      <td>8.887154e-07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>65040934f049f672e58adc4a</td>\n",
       "      <td>comando/alagamento/93901/1026/CODE1026 2023-03...</td>\n",
       "      <td>8.380167e-09</td>\n",
       "      <td>1.136922e-08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          _id  \\\n",
       "89   65040934f049f672e58adc46   \n",
       "2    65040934f049f672e58adc47   \n",
       "90   65040934f049f672e58adc48   \n",
       "200  65040934f049f672e58adc49   \n",
       "91   65040934f049f672e58adc4a   \n",
       "\n",
       "                                             blob_name     prob_mean  \\\n",
       "89   comando/alagamento/93901/1026/CODE1026 2023-03...  9.371731e-04   \n",
       "2    comando/alagamento/93901/1026/CODE1026 2023-03...  9.260222e-04   \n",
       "90   comando/alagamento/93901/1026/CODE1026 2023-03...  2.225615e-09   \n",
       "200  comando/alagamento/93901/1026/CODE1026 2023-03...  1.630687e-07   \n",
       "91   comando/alagamento/93901/1026/CODE1026 2023-03...  8.380167e-09   \n",
       "\n",
       "         prob_std  pred  \n",
       "89   1.059198e-04   0.0  \n",
       "2    1.356357e-04   0.0  \n",
       "90   2.815121e-09   0.0  \n",
       "200  8.887154e-07   0.0  \n",
       "91   1.136922e-08   0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (20751, 5)\n",
      "\n",
      "pred\n",
      "0.0    19149\n",
      "1.0     1489\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "preds_path = 'data/datasets-full/images_pred/images_pred_old.csv'\n",
    "\n",
    "preds = pd.read_csv(preds_path)\n",
    "\n",
    "df_images_predicted = df_images.loc[preds['index']]\n",
    "\n",
    "df_images_predicted[['prob', 'pred']] = preds[['prob', 'pred']].values\n",
    "\n",
    "video_prob_stats = df_images_predicted.groupby(['id_video'])['prob'].agg(['mean', 'std'])\n",
    "video_prob_stats.columns = ['prob_mean', 'prob_std']\n",
    "video_pred = df_images_predicted.groupby(['id_video'])['pred'].max()\n",
    "\n",
    "videos_predicted = pd.concat([video_prob_stats, video_pred], axis=1)\n",
    "\n",
    "# Merge additional video data\n",
    "videos_predicted = df_videos[['_id', 'blob_name']].join(videos_predicted, on='_id', how='right')\n",
    "\n",
    "display(videos_predicted.head())\n",
    "\n",
    "print('Shape:', videos_predicted.shape)\n",
    "print()\n",
    "print(videos_predicted['pred'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5341b95-e89a-4200-b9e4-a01d8e89ac58",
   "metadata": {},
   "source": [
    "#### Analyze errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ef6c6bf1-5c01-4c77-bd68-6cffa112f034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_start</th>\n",
       "      <th>index_end</th>\n",
       "      <th>batch_index</th>\n",
       "      <th>error</th>\n",
       "      <th>traceback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56672</td>\n",
       "      <td>56687</td>\n",
       "      <td>3542</td>\n",
       "      <td>cannot identify image file 'data/images/polygo...</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"C:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56688</td>\n",
       "      <td>56703</td>\n",
       "      <td>3543</td>\n",
       "      <td>cannot identify image file 'data/images/polygo...</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"C:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56704</td>\n",
       "      <td>56719</td>\n",
       "      <td>3544</td>\n",
       "      <td>cannot identify image file 'data/images/polygo...</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"C:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57584</td>\n",
       "      <td>57599</td>\n",
       "      <td>3599</td>\n",
       "      <td>cannot identify image file 'data/images/polygo...</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"C:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57600</td>\n",
       "      <td>57615</td>\n",
       "      <td>3600</td>\n",
       "      <td>cannot identify image file 'data/images/polygo...</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"C:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index_start  index_end  batch_index  \\\n",
       "0        56672      56687         3542   \n",
       "1        56688      56703         3543   \n",
       "2        56704      56719         3544   \n",
       "3        57584      57599         3599   \n",
       "4        57600      57615         3600   \n",
       "\n",
       "                                               error  \\\n",
       "0  cannot identify image file 'data/images/polygo...   \n",
       "1  cannot identify image file 'data/images/polygo...   \n",
       "2  cannot identify image file 'data/images/polygo...   \n",
       "3  cannot identify image file 'data/images/polygo...   \n",
       "4  cannot identify image file 'data/images/polygo...   \n",
       "\n",
       "                                           traceback  \n",
       "0  Traceback (most recent call last):\\n  File \"C:...  \n",
       "1  Traceback (most recent call last):\\n  File \"C:...  \n",
       "2  Traceback (most recent call last):\\n  File \"C:...  \n",
       "3  Traceback (most recent call last):\\n  File \"C:...  \n",
       "4  Traceback (most recent call last):\\n  File \"C:...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (593, 5) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "errors_path = 'data/datasets-full/images_pred/errors.json'\n",
    "\n",
    "errors = pd.DataFrame(json.load(open(errors_path, 'r')))\n",
    "\n",
    "display(errors.head())\n",
    "print('Shape:', errors.shape, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74710835-b4c1-41bf-b760-32d577e0fdda",
   "metadata": {},
   "source": [
    "#### Post video classification results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70d83cc3-4b35-4f43-82d4-ee82d29bb9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESSED: 2119 / 2119 | POSTED: 2119 / 2119 | TIME-RUNNING: 1.38 min / 34.12 min | TIME-LEFT: 0.0 min | ERRORS: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from IPython.display import clear_output as co\n",
    "\n",
    "bucket = 'flood-videos-stamped'\n",
    "progress_path = 'data/datasets-full/images_pred_post/progress.json'\n",
    "error_path = 'data/datasets-full/images_pred_post/errors.json'\n",
    "save_each = 25\n",
    "id_field = '_id'\n",
    "df = videos_predicted[videos_predicted['pred'] == 1].copy()\n",
    "\n",
    "base_url = 'https://watch-bucket-veuei2iu4q-uc.a.run.app'\n",
    "# base_url = 'http://localhost:8080'\n",
    "video_tags = VideoTags(base_url)\n",
    "\n",
    "progress = {idx: False for idx in df['_id']}\n",
    "if os.path.exists(progress_path):\n",
    "    progress_saved = json.load(open(progress_path, 'r'))\n",
    "    progress = {**progress, **progress_saved}\n",
    "\n",
    "done = sum(list(progress.values()))\n",
    "done_start = done\n",
    "\n",
    "errors = []\n",
    "if os.path.exists(error_path):\n",
    "    errors = json.load(open(error_path, 'r'))\n",
    "\n",
    "n_videos = len(df)\n",
    "s_time = time.time()\n",
    "\n",
    "for i, (idx, row) in enumerate(df.iterrows()):\n",
    "    \n",
    "    e_time = time.time() - s_time\n",
    "    e_time_round = round(e_time / 60, 2)\n",
    "    avg_time = e_time / max(1, done - done_start)\n",
    "    expected_finish_time = round((n_videos - done) * avg_time / 60, 2)\n",
    "    expected_total_time = round((n_videos - done_start) * avg_time  / 60, 2)\n",
    "\n",
    "    co(True)\n",
    "    print(f'PROCESSED: {i} / {n_videos} | POSTED: {done} / {n_videos} | TIME-RUNNING: {e_time_round} min / {expected_total_time} min | TIME-LEFT: {expected_finish_time} min | ERRORS: {len(errors)}')    \n",
    "\n",
    "    id_video = row['_id']\n",
    "    blob_name = row['blob_name']\n",
    "    prob_mean = row['prob_mean']\n",
    "    prob_std = row['prob_std']\n",
    "    pred = row['pred']\n",
    "\n",
    "    tags = ['acúmulo-ia' if pred is not None and pred else 'normal-ia']\n",
    "\n",
    "    if not progress[id_video]:\n",
    "        data = video_tags.post(tags, blob_name, bucket)\n",
    "        \n",
    "        success = data['status'] and data['data'] is not None and 'message' in data['data'] and 'successfully' in data['data']['message']\n",
    "        \n",
    "        if success:\n",
    "            progress[id_video] = True\n",
    "            done += 1\n",
    "        \n",
    "        else:\n",
    "            errors.append({'id_video': id_video, **data})\n",
    "            \n",
    "    if (i + 1) % save_each == 0 or (i + 1) == n_videos:\n",
    "        with open(progress_path, 'w') as fw:\n",
    "            fw.write(json.dumps(progress))\n",
    "            \n",
    "        with open(error_path, 'w') as fw:\n",
    "            fw.write(json.dumps(errors))\n",
    "\n",
    "    co(True)\n",
    "    print(f'PROCESSED: {i + 1} / {n_videos} | POSTED: {done} / {n_videos} | TIME-RUNNING: {e_time_round} min / {expected_total_time} min | TIME-LEFT: {expected_finish_time} min | ERRORS: {len(errors)}')    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
