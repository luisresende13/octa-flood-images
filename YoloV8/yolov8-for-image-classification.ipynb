{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7521839,"sourceType":"datasetVersion","datasetId":4381757}],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Install modules","metadata":{"execution":{"iopub.status.busy":"2024-01-12T18:40:00.439277Z","iopub.execute_input":"2024-01-12T18:40:00.440168Z","iopub.status.idle":"2024-01-12T18:40:14.890085Z","shell.execute_reply.started":"2024-01-12T18:40:00.440131Z","shell.execute_reply":"2024-01-12T18:40:14.889111Z"}}},{"cell_type":"code","source":"!pip install -U ultralytics\n!pip install -U ipywidgets\n\n# May need to restart the notebook after installation","metadata":{"execution":{"iopub.status.busy":"2024-01-31T15:07:19.716320Z","iopub.execute_input":"2024-01-31T15:07:19.716628Z","iopub.status.idle":"2024-01-31T15:07:50.417160Z","shell.execute_reply.started":"2024-01-31T15:07:19.716602Z","shell.execute_reply":"2024-01-31T15:07:50.416171Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting ultralytics\n  Obtaining dependency information for ultralytics from https://files.pythonhosted.org/packages/c1/45/68650eb444bbe0bc762aa2a5007f9f4ff613709165b579e1760cd0c65fbd/ultralytics-8.1.8-py3-none-any.whl.metadata\n  Downloading ultralytics-8.1.8-py3-none-any.whl.metadata (40 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.2/40.2 kB\u001b[0m \u001b[31m685.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (3.7.4)\nRequirement already satisfied: numpy>=1.22.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.24.3)\nRequirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.9.0.80)\nRequirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.5.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (6.0.1)\nRequirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.31.0)\nRequirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.11.4)\nRequirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.0.0)\nRequirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.15.1)\nRequirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.66.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ultralytics) (5.9.3)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.0.0)\nCollecting thop>=0.1.1 (from ultralytics)\n  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\nRequirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.0.3)\nRequirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.12.2)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.1.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.42.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2023.11.17)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\nDownloading ultralytics-8.1.8-py3-none-any.whl (709 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m709.4/709.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: thop, ultralytics\nSuccessfully installed thop-0.1.1.post2209072238 ultralytics-8.1.8\nRequirement already satisfied: ipywidgets in /opt/conda/lib/python3.10/site-packages (7.7.1)\nCollecting ipywidgets\n  Obtaining dependency information for ipywidgets from https://files.pythonhosted.org/packages/4a/0e/57ed498fafbc60419a9332d872e929879ceba2d73cb11d284d7112472b3e/ipywidgets-8.1.1-py3-none-any.whl.metadata\n  Downloading ipywidgets-8.1.1-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (0.1.4)\nRequirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (8.14.0)\nRequirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (5.9.0)\nCollecting widgetsnbextension~=4.0.9 (from ipywidgets)\n  Obtaining dependency information for widgetsnbextension~=4.0.9 from https://files.pythonhosted.org/packages/29/03/107d96077c4befed191f7ad1a12c7b52a8f9d2778a5836d59f9855c105f6/widgetsnbextension-4.0.9-py3-none-any.whl.metadata\n  Downloading widgetsnbextension-4.0.9-py3-none-any.whl.metadata (1.6 kB)\nCollecting jupyterlab-widgets~=3.0.9 (from ipywidgets)\n  Obtaining dependency information for jupyterlab-widgets~=3.0.9 from https://files.pythonhosted.org/packages/e8/05/0ebab152288693b5ec7b339aab857362947031143b282853b4c2dd4b5b40/jupyterlab_widgets-3.0.9-py3-none-any.whl.metadata\n  Downloading jupyterlab_widgets-3.0.9-py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: backcall in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.0)\nRequirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\nRequirement already satisfied: pickleshare in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.39)\nRequirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.16.1)\nRequirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\nRequirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\nRequirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\nRequirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\nDownloading ipywidgets-8.1.1-py3-none-any.whl (139 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m0m\n\u001b[?25hDownloading jupyterlab_widgets-3.0.9-py3-none-any.whl (214 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m214.9/214.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading widgetsnbextension-4.0.9-py3-none-any.whl (2.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\n  Attempting uninstall: widgetsnbextension\n    Found existing installation: widgetsnbextension 3.6.6\n    Uninstalling widgetsnbextension-3.6.6:\n      Successfully uninstalled widgetsnbextension-3.6.6\n  Attempting uninstall: jupyterlab-widgets\n    Found existing installation: jupyterlab-widgets 3.0.8\n    Uninstalling jupyterlab-widgets-3.0.8:\n      Successfully uninstalled jupyterlab-widgets-3.0.8\n  Attempting uninstall: ipywidgets\n    Found existing installation: ipywidgets 7.7.1\n    Uninstalling ipywidgets-7.7.1:\n      Successfully uninstalled ipywidgets-7.7.1\nSuccessfully installed ipywidgets-8.1.1 jupyterlab-widgets-3.0.9 widgetsnbextension-4.0.9\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Set tensorboard or comet for monitoring","metadata":{}},{"cell_type":"code","source":"logger = 'Comet' #@param ['Comet', 'TensorBoard']\n\ncomet_key = '053dXzGWtieRxHSx26aTnUTCC'\n\nif logger == 'Comet':\n  %pip install -q comet_ml\n  import comet_ml; comet_ml.init()\nelif logger == 'TensorBoard':\n  %load_ext tensorboard\n  %tensorboard --logdir /content/runs/detect/train","metadata":{"execution":{"iopub.status.busy":"2024-01-31T15:07:50.419079Z","iopub.execute_input":"2024-01-31T15:07:50.419474Z","iopub.status.idle":"2024-01-31T15:09:56.829480Z","shell.execute_reply.started":"2024-01-31T15:07:50.419440Z","shell.execute_reply":"2024-01-31T15:09:56.828545Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\njupyterlab 4.0.10 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\nPlease paste your Comet API key from https://www.comet.com/api/my/settings/\n(api key may not show as you type)\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Comet API key:  Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"},{"name":"stderr","text":"\u001b[1;38;5;39mCOMET INFO:\u001b[0m Valid Comet API Key saved in /root/.comet.config (set COMET_CONFIG to change where it is saved).\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Set wand for monitoring","metadata":{}},{"cell_type":"code","source":"import wandb\n\nwandb.login(key='36ee4712b2b266eaa23e05b4d07f16fbee9f5a1e')","metadata":{"execution":{"iopub.status.busy":"2024-01-31T15:09:56.830606Z","iopub.execute_input":"2024-01-31T15:09:56.830911Z","iopub.status.idle":"2024-01-31T15:10:00.074984Z","shell.execute_reply.started":"2024-01-31T15:09:56.830885Z","shell.execute_reply":"2024-01-31T15:10:00.074129Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"markdown","source":"### Clear 'runs' directories","metadata":{}},{"cell_type":"code","source":"!rm -r runs\n# !rm -r results","metadata":{"execution":{"iopub.status.busy":"2024-01-31T15:10:00.076662Z","iopub.execute_input":"2024-01-31T15:10:00.077077Z","iopub.status.idle":"2024-01-31T15:10:01.195159Z","shell.execute_reply.started":"2024-01-31T15:10:00.077051Z","shell.execute_reply":"2024-01-31T15:10:01.193730Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Train yolo model","metadata":{}},{"cell_type":"code","source":"from ultralytics import YOLO\n\n# Load a model\nmodel = YOLO('models/yolov8m-cls.pt')  # load a pretrained model (recommended for training)\n\n# Define train parameters\nparams = {\n    'data': '../input/flood-images-split/sgkf-8-1-1',\n    'epochs': 300,\n    'imgsz': 640,\n    'batch': 16,\n    'device': [0, 1],\n    'optimizer': 'Adam',\n    'lr0': 0.000000001,\n    'lrf': 0.000000001, # default: 0.01\n    'momentum': 0.9, # default: 0.937\n    'patience': 5,\n#     'plots': True,\n#     'single_cls': False,\n#     'label_smoothing': 0.0\n}\n\n# Train the model\nresults = model.train(**params)","metadata":{"execution":{"iopub.status.busy":"2024-01-31T16:11:40.598724Z","iopub.execute_input":"2024-01-31T16:11:40.599555Z","iopub.status.idle":"2024-01-31T16:19:44.778975Z","shell.execute_reply.started":"2024-01-31T16:11:40.599519Z","shell.execute_reply":"2024-01-31T16:19:44.777965Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Ultralytics YOLOv8.1.8 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15102MiB)\n                                                     CUDA:1 (Tesla T4, 15102MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=models/yolov8m-cls.pt, data=../input/flood-images-split/sgkf-8-1-1, epochs=300, time=None, patience=5, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=[0, 1], workers=8, project=None, name=train4, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=1e-09, lrf=1e-09, momentum=0.9, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/train4\n\u001b[34m\u001b[1mtrain:\u001b[0m /kaggle/input/flood-images-split/sgkf-8-1-1/train... found 1706 images in 2 classes âœ… \n\u001b[34m\u001b[1mval:\u001b[0m /kaggle/input/flood-images-split/sgkf-8-1-1/val... found 225 images in 2 classes âœ… \n\u001b[34m\u001b[1mtest:\u001b[0m /kaggle/input/flood-images-split/sgkf-8-1-1/test... found 231 images in 2 classes âœ… \nOverriding model.yaml nc=1000 with nc=2\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n  7                  -1  1   2655744  ultralytics.nn.modules.conv.Conv             [384, 768, 3, 2]              \n  8                  -1  2   7084032  ultralytics.nn.modules.block.C2f             [768, 768, 2, True]           \n  9                  -1  1    988162  ultralytics.nn.modules.head.Classify         [768, 2]                      \nYOLOv8m-cls summary: 141 layers, 15774898 parameters, 15774898 gradients, 41.9 GFLOPs\nTransferred 228/230 items from pretrained weights\n\u001b[34m\u001b[1mDDP:\u001b[0m debug command /opt/conda/bin/python3.10 -m torch.distributed.run --nproc_per_node 2 --master_port 56523 /root/.config/Ultralytics/DDP/_temp_dm7e4kge140467047003424.py\nUltralytics YOLOv8.1.8 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15102MiB)\n                                                     CUDA:1 (Tesla T4, 15102MiB)\n\u001b[34m\u001b[1mtrain:\u001b[0m /kaggle/input/flood-images-split/sgkf-8-1-1/train... found 1706 images in 2 classes âœ… \n\u001b[34m\u001b[1mval:\u001b[0m /kaggle/input/flood-images-split/sgkf-8-1-1/val... found 225 images in 2 classes âœ… \n\u001b[34m\u001b[1mtest:\u001b[0m /kaggle/input/flood-images-split/sgkf-8-1-1/test... found 231 images in 2 classes âœ… \n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/kaggle/working' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com \u001b[38;5;39mhttps://www.comet.com/luisresende13/general/fa778befed5243f68887099173633da5\u001b[0m\n\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/classify/train4', view at http://localhost:6006/\n","output_type":"stream"},{"name":"stderr","text":"wandb: Currently logged in as: luisresende13 (octacity). Use `wandb login --relogin` to force relogin\nwandb: Tracking run with wandb version 0.16.2\nwandb: Run data is saved locally in /kaggle/working/wandb/run-20240131_161157-1b2hqxuc\nwandb: Run `wandb offline` to turn off syncing.\nwandb: Syncing run train4\nwandb: â­ï¸ View project at https://wandb.ai/octacity/YOLOv8\nwandb: ðŸš€ View run at https://wandb.ai/octacity/YOLOv8/runs/1b2hqxuc\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/flood-images-split/sgkf-8-1-1/train... 1706 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1706/1706 [00:01<00:00, 1123.38it/s]\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/flood-images-split/sgkf-8-1-1/train...:   0%|          | 0/1706 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ Cache directory /kaggle/input/flood-images-split/sgkf-8-1-1 is not writeable, cache not saved.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/flood-images-split/sgkf-8-1-1/val... 225 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:00<00:00, 1096.26it/s]it/s]\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/flood-images-split/sgkf-8-1-1/train... 458 images, 0 corrupt:  27%|â–ˆâ–ˆâ–‹       | 458/1706 [00:00<00:01, 1133.93it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ Cache directory /kaggle/input/flood-images-split/sgkf-8-1-1 is not writeable, cache not saved.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/flood-images-split/sgkf-8-1-1/train... 692 images, 0 corrupt:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 692/1706 [00:00<00:00, 1143.77it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=1e-09, momentum=0.9) with parameter groups 38 weight(decay=0.0), 39 weight(decay=0.0005), 39 bias(decay=0.0)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/flood-images-split/sgkf-8-1-1/train... 1706 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1706/1706 [00:01<00:00, 1132.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/classify/train4\u001b[0m\nStarting training for 300 epochs...\n\n      Epoch    GPU_mem       loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      1/300      2.48G      1.095          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 107/107 [00:48<00:00,  2.19it/s]\n               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:04<00:00,  3.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       0.48          1\n\n      Epoch    GPU_mem       loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      2/300      2.75G     0.8038          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 107/107 [00:34<00:00,  3.08it/s]\n               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:03<00:00,  4.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      0.609          1\n\n      Epoch    GPU_mem       loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      3/300      2.73G     0.7242          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 107/107 [00:35<00:00,  3.03it/s]\n               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:03<00:00,  4.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      0.698          1\n\n      Epoch    GPU_mem       loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      4/300      2.74G     0.6821          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 107/107 [00:32<00:00,  3.24it/s]\n               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:03<00:00,  4.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      0.693          1\n\n      Epoch    GPU_mem       loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      5/300      2.73G     0.6895          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 107/107 [00:33<00:00,  3.22it/s]\n               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:03<00:00,  4.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      0.738          1\n\n      Epoch    GPU_mem       loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      6/300      2.74G     0.7166          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 107/107 [00:33<00:00,  3.22it/s]\n               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:03<00:00,  4.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      0.711          1\n\n      Epoch    GPU_mem       loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      7/300      2.74G     0.6839          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 107/107 [00:32<00:00,  3.30it/s]\n               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:03<00:00,  4.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      0.698          1\n\n      Epoch    GPU_mem       loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      8/300      2.74G     0.6585          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 107/107 [00:33<00:00,  3.15it/s]\n               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:03<00:00,  4.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      0.693          1\n\n      Epoch    GPU_mem       loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      9/300      2.73G     0.6546          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 107/107 [00:38<00:00,  2.78it/s]\n               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:03<00:00,  4.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      0.698          1\n\n      Epoch    GPU_mem       loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     10/300      2.73G     0.6206          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 107/107 [00:34<00:00,  3.12it/s]\n               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:03<00:00,  4.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      0.702          1\nStopping training early as no improvement observed in last 5 epochs. Best results observed at epoch 5, best model saved as best.pt.\nTo update EarlyStopping(patience=5) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n\n10 epochs completed in 0.114 hours.\nOptimizer stripped from runs/classify/train4/weights/last.pt, 31.7MB\nOptimizer stripped from runs/classify/train4/weights/best.pt, 31.7MB\n\nValidating runs/classify/train4/weights/best.pt...\nUltralytics YOLOv8.1.8 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15102MiB)\nYOLOv8m-cls summary (fused): 103 layers, 15765218 parameters, 0 gradients, 41.6 GFLOPs\n\u001b[34m\u001b[1mtrain:\u001b[0m /kaggle/input/flood-images-split/sgkf-8-1-1/train... found 1706 images in 2 classes âœ… \n\u001b[34m\u001b[1mval:\u001b[0m /kaggle/input/flood-images-split/sgkf-8-1-1/val... found 225 images in 2 classes âœ… \n\u001b[34m\u001b[1mtest:\u001b[0m /kaggle/input/flood-images-split/sgkf-8-1-1/test... found 231 images in 2 classes âœ… \n","output_type":"stream"},{"name":"stderr","text":"               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:03<00:00,  4.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      0.738          1\nSpeed: 1.5ms preprocess, 5.5ms inference, 0.0ms loss, 0.0ms postprocess per image\nResults saved to \u001b[1mruns/classify/train4\u001b[0m\nResults saved to \u001b[1mruns/classify/train4\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"\u001b[1;38;5;196mCOMET ERROR:\u001b[0m We failed to read file runs/classify/train4/F1_curve.png for uploading.\nPlease double-check the file path and permissions\n\u001b[1;38;5;196mCOMET ERROR:\u001b[0m We failed to read file runs/classify/train4/P_curve.png for uploading.\nPlease double-check the file path and permissions\n\u001b[1;38;5;196mCOMET ERROR:\u001b[0m We failed to read file runs/classify/train4/R_curve.png for uploading.\nPlease double-check the file path and permissions\n\u001b[1;38;5;196mCOMET ERROR:\u001b[0m We failed to read file runs/classify/train4/PR_curve.png for uploading.\nPlease double-check the file path and permissions\n\u001b[1;38;5;196mCOMET ERROR:\u001b[0m We failed to read file runs/classify/train4/labels.jpg for uploading.\nPlease double-check the file path and permissions\n\u001b[1;38;5;196mCOMET ERROR:\u001b[0m We failed to read file runs/classify/train4/labels_correlogram.jpg for uploading.\nPlease double-check the file path and permissions\n\u001b[1;38;5;196mCOMET ERROR:\u001b[0m Error logging confusion matrix; ignoring\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : \u001b[38;5;39mhttps://www.comet.com/luisresende13/general/fa778befed5243f68887099173633da5\u001b[0m\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg0 [21]                : (9.733333333600001e-10, 0.06697819347663551)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg1 [21]                : (3.3021806853582555e-10, 9.902388369744549e-10)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg2 [21]                : (3.3021806853582555e-10, 9.902388369744549e-10)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/accuracy_top1 [22] : (0.48, 0.73778)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/accuracy_top5      : 1.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/GFLOPs               : 41.893\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/parameters           : 15774898\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/speed_PyTorch(ms)    : 7.015\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/loss [20]            : (0.62056, 1.09513)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/loss [20]              : (0.53665, 0.71725)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_batch_logging_interval  : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_confusion_matrix_on_eval : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_image_predictions        : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_image_predictions        : 100\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     agnostic_nms    : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     amp             : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     augment         : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     auto_augment    : randaugment\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch           : 16\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     box             : 7.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cache           : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cfg             : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     classes         : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     close_mosaic    : 10\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls             : 0.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conf            : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste      : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cos_lr          : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     crop_fraction   : 1.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     data            : ../input/flood-images-split/sgkf-8-1-1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     degrees         : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     deterministic   : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     device          : [0, 1]\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dfl             : 1.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dnn             : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout         : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dynamic         : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     embed           : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epochs          : 300\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     erasing         : 0.4\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     exist_ok        : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fliplr          : 0.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flipud          : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     format          : torchscript\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fraction        : 1.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     freeze          : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     half            : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_h           : 0.015\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_s           : 0.7\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_v           : 0.4\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imgsz           : 640\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     int8            : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     iou             : 0.7\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     keras           : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     kobj            : 1.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     label_smoothing : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     line_width      : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr0             : 1e-09\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lrf             : 1e-09\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mask_ratio      : 4\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_det         : 300\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mixup           : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mode            : train\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model           : models/yolov8m-cls.pt\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum        : 0.9\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mosaic          : 1.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     multi_scale     : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name            : train4\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nbs             : 64\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nms             : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     opset           : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimize        : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer       : Adam\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     overlap_mask    : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     patience        : 5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     perspective     : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     plots           : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pose            : 12.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pretrained      : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     profile         : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project         : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rect            : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume          : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     retina_masks    : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save            : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_conf       : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_crop       : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_dir        : runs/classify/train4\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_frames     : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_hybrid     : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_json       : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_period     : -1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_txt        : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     scale           : 0.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed            : 0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     shear           : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show            : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_boxes      : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_conf       : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_labels     : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     simplify        : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     single_cls      : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source          : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     split           : val\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     stream_buffer   : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     task            : classify\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     time            : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tracker         : botsort.yaml\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     translate       : 0.1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val             : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     verbose         : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vid_stride      : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualize       : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_bias_lr  : 0.1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_epochs   : 3.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_momentum : 0.8\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weight_decay    : 0.0005\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workers         : 8\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workspace       : 4\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-environment-definition : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-info                   : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-specification          : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details          : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                     : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images                       : 4\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages           : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element                : 1 (30.22 MB)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages                  : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code                  : 2 (15.72 KB)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for metadata to finish uploading (timeout is 3600 seconds)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Uploading 132 metrics, params and output messages\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Zip and download results folder","metadata":{}},{"cell_type":"code","source":"import shutil\n\n#  Function to zip a folder\ndef zip_folder(folder_path, zip_filename):\n    # Create a zip file using shutil\n    shutil.make_archive(zip_filename.split('.zip')[0], 'zip', folder_path)\n\n    # Move the created zip file to the correct path\n    shutil.move(zip_filename.split('.zip')[0] + '.zip', zip_filename)\n\n\ntrain_index = ''\n\n# Path to the folder you want to zip\nfolder_path = f'runs/classify/train{train_index}'\n\n# Path to save the zip file\nzip_filename = 'results/sgkf-8-1-1-epochs23.zip'\n\n# Zip the folder\nzip_folder(folder_path, zip_filename)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Unzip folder with results","metadata":{}},{"cell_type":"code","source":"import zipfile\nimport os\n\n# Function to unzip a zip file\ndef unzip_folder(zip_file_path, extracted_dir_path):\n    # Create the directory if it doesn't exist\n    os.makedirs(extracted_dir_path, exist_ok=True)\n\n    # Extract the contents of the zip file\n    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n        zip_ref.extractall(extracted_dir_path)\n\n    print(f\"Contents of {zip_file_path} have been successfully extracted to {extracted_dir_path}.\")\n\n\n# Specify the path to your zip file\nzip_file_path = 'results/n-2.zip'\n\ntrain_index = ''\n\n# Specify the directory where you want to extract the contents\nextracted_dir_path = f'runs/classify/train{train_index}'\n\n# Unzip the contents of the zip file\nunzip_folder(zip_file_path, extracted_dir_path)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Resume interrupted training","metadata":{}},{"cell_type":"code","source":"16from ultralytics import YOLO\n\ntrain_index = ''\n\n# Path to yolo `runs/detect/train` folder\nfolder_path = f'runs/classify/train{train_index}'\n\n# Define train parameters\nparams = {\n    'data': '../input/flood-images-split/under-10058-StratifiedGroupKFold-5',\n    'epochs': 100,\n    'imgsz': 640,\n    'batch': 16,\n    'device': [0, 1],\n    'single_cls': False,\n    'label_smoothing': 0.0\n}\n\n\n# Load a model\nmodel = YOLO(f'{folder_path}/weights/last.pt')  # load a partially trained model\n\n# Resume training\nresults = model.train(**params, resume=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluate model","metadata":{}},{"cell_type":"code","source":"from ultralytics import YOLO\n\ntrain_index = '4'\n\n# Path to the folder you want to zip\nfolder_path = f'runs/classify/train{train_index}'\n\n# Define eval parameters\nparams = {\n    'data': '../input/flood-images-split/sgkf-8-1-1',\n    'imgsz': 640,\n    'batch': 16,\n    'device': [0, 1],\n    'split': 'val',\n#     'single_cls': False,\n#     'label_smoothing': 0.0\n}\n\n# Load a model\nmodel = YOLO(f'{folder_path}/weights/best.pt')  # load a partially trained model\n\n# Validate the model\nmetrics = model.val(**params)  # no arguments needed, dataset and settings remembered\n\n# Print the metrics\n{\n    'top1': metrics.top1,\n    'top5': metrics.top5,\n}","metadata":{"execution":{"iopub.status.busy":"2024-01-31T16:19:44.780529Z","iopub.execute_input":"2024-01-31T16:19:44.781251Z","iopub.status.idle":"2024-01-31T16:19:52.807415Z","shell.execute_reply.started":"2024-01-31T16:19:44.781220Z","shell.execute_reply":"2024-01-31T16:19:52.806191Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Ultralytics YOLOv8.1.8 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15102MiB)\n                                                     CUDA:1 (Tesla T4, 15102MiB)\nYOLOv8m-cls summary (fused): 103 layers, 15765218 parameters, 0 gradients, 41.6 GFLOPs\n\u001b[34m\u001b[1mtrain:\u001b[0m /kaggle/input/flood-images-split/sgkf-8-1-1/train... found 1706 images in 2 classes âœ… \n\u001b[34m\u001b[1mval:\u001b[0m /kaggle/input/flood-images-split/sgkf-8-1-1/val... found 225 images in 2 classes âœ… \n\u001b[34m\u001b[1mtest:\u001b[0m /kaggle/input/flood-images-split/sgkf-8-1-1/test... found 231 images in 2 classes âœ… \n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/flood-images-split/sgkf-8-1-1/val... 225 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:00<00:00, 1145.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ Cache directory /kaggle/input/flood-images-split/sgkf-8-1-1 is not writeable, cache not saved.\n","output_type":"stream"},{"name":"stderr","text":"               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:04<00:00,  3.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      0.738          1\nSpeed: 1.9ms preprocess, 11.9ms inference, 0.0ms loss, 0.0ms postprocess per image\nResults saved to \u001b[1mruns/classify/val\u001b[0m\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"{'top1': 0.7377777695655823, 'top5': 1.0}"},"metadata":{}}]},{"cell_type":"code","source":"from ultralytics import YOLO\n\ntrain_index = '4'\n\n# Path to the folder you want to zip\nfolder_path = f'runs/classify/train{train_index}'\n\n# Define eval parameters\nparams = {\n    'data': '../input/flood-images-split/sgkf-8-1-1',\n    'imgsz': 640,\n    'batch': 16,\n    'device': [0, 1],\n    'split': 'test',\n#     'single_cls': False,\n#     'label_smoothing': 0.0\n}\n\n# Load a model\nmodel = YOLO(f'{folder_path}/weights/best.pt')  # load a partially trained model\n\n# Validate the model\nmetrics = model.val(**params)  # no arguments needed, dataset and settings remembered\n\n# Print the metrics\n{\n    'top1': metrics.top1,\n    'top5': metrics.top5,\n}","metadata":{"execution":{"iopub.status.busy":"2024-01-31T16:19:52.809792Z","iopub.execute_input":"2024-01-31T16:19:52.810227Z","iopub.status.idle":"2024-01-31T16:20:01.407502Z","shell.execute_reply.started":"2024-01-31T16:19:52.810189Z","shell.execute_reply":"2024-01-31T16:20:01.406535Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Ultralytics YOLOv8.1.8 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15102MiB)\n                                                     CUDA:1 (Tesla T4, 15102MiB)\nYOLOv8m-cls summary (fused): 103 layers, 15765218 parameters, 0 gradients, 41.6 GFLOPs\n\u001b[34m\u001b[1mtrain:\u001b[0m /kaggle/input/flood-images-split/sgkf-8-1-1/train... found 1706 images in 2 classes âœ… \n\u001b[34m\u001b[1mval:\u001b[0m /kaggle/input/flood-images-split/sgkf-8-1-1/val... found 225 images in 2 classes âœ… \n\u001b[34m\u001b[1mtest:\u001b[0m /kaggle/input/flood-images-split/sgkf-8-1-1/test... found 231 images in 2 classes âœ… \n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtest: \u001b[0mScanning /kaggle/input/flood-images-split/sgkf-8-1-1/test... 231 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 231/231 [00:00<00:00, 306.38it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtest: \u001b[0mWARNING âš ï¸ Cache directory /kaggle/input/flood-images-split/sgkf-8-1-1 is not writeable, cache not saved.\n","output_type":"stream"},{"name":"stderr","text":"\n               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      0.619          1\nSpeed: 1.7ms preprocess, 11.4ms inference, 0.0ms loss, 0.0ms postprocess per image\nResults saved to \u001b[1mruns/classify/val2\u001b[0m\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"{'top1': 0.6190476417541504, 'top5': 1.0}"},"metadata":{}}]}]}