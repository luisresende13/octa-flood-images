{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7640427,"sourceType":"datasetVersion","datasetId":4452913},{"sourceId":7640446,"sourceType":"datasetVersion","datasetId":4452928}],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Install modules","metadata":{"execution":{"iopub.status.busy":"2024-01-12T18:40:00.439277Z","iopub.execute_input":"2024-01-12T18:40:00.440168Z","iopub.status.idle":"2024-01-12T18:40:14.890085Z","shell.execute_reply.started":"2024-01-12T18:40:00.440131Z","shell.execute_reply":"2024-01-12T18:40:14.889111Z"}}},{"cell_type":"code","source":"!pip install -U ultralytics\n!pip install -U ipywidgets\n\n# May need to restart the notebook after installation","metadata":{"execution":{"iopub.status.busy":"2024-02-17T12:06:33.555291Z","iopub.execute_input":"2024-02-17T12:06:33.555688Z","iopub.status.idle":"2024-02-17T12:07:01.408580Z","shell.execute_reply.started":"2024-02-17T12:06:33.555643Z","shell.execute_reply":"2024-02-17T12:07:01.407423Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting ultralytics\n  Obtaining dependency information for ultralytics from https://files.pythonhosted.org/packages/eb/b7/58789e8888aa026d8ea72ba736b267e54219c31a00c0f16da77e618255bd/ultralytics-8.1.14-py3-none-any.whl.metadata\n  Downloading ultralytics-8.1.14-py3-none-any.whl.metadata (40 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.2/40.2 kB\u001b[0m \u001b[31m765.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (3.7.4)\nRequirement already satisfied: numpy>=1.22.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.24.3)\nRequirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.9.0.80)\nRequirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.5.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (6.0.1)\nRequirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.31.0)\nRequirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.11.4)\nRequirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.0.0)\nRequirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.15.1)\nRequirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.66.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ultralytics) (5.9.3)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.0.0)\nCollecting thop>=0.1.1 (from ultralytics)\n  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\nRequirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.0.3)\nRequirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.12.2)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.1.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.42.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2023.11.17)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\nDownloading ultralytics-8.1.14-py3-none-any.whl (715 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m715.0/715.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: thop, ultralytics\nSuccessfully installed thop-0.1.1.post2209072238 ultralytics-8.1.14\nRequirement already satisfied: ipywidgets in /opt/conda/lib/python3.10/site-packages (7.7.1)\nCollecting ipywidgets\n  Obtaining dependency information for ipywidgets from https://files.pythonhosted.org/packages/70/1a/7edeedb1c089d63ccd8bd5c0612334774e90cf9337de9fe6c82d90081791/ipywidgets-8.1.2-py3-none-any.whl.metadata\n  Downloading ipywidgets-8.1.2-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (0.1.4)\nRequirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (8.14.0)\nRequirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (5.9.0)\nCollecting widgetsnbextension~=4.0.10 (from ipywidgets)\n  Obtaining dependency information for widgetsnbextension~=4.0.10 from https://files.pythonhosted.org/packages/99/bc/82a8c3985209ca7c0a61b383c80e015fd92e74f8ba0ec1af98f9d6ca8dce/widgetsnbextension-4.0.10-py3-none-any.whl.metadata\n  Downloading widgetsnbextension-4.0.10-py3-none-any.whl.metadata (1.6 kB)\nCollecting jupyterlab-widgets~=3.0.10 (from ipywidgets)\n  Obtaining dependency information for jupyterlab-widgets~=3.0.10 from https://files.pythonhosted.org/packages/24/da/db1cb0387a7e4086780aff137987ee924e953d7f91b2a870f994b9b1eeb8/jupyterlab_widgets-3.0.10-py3-none-any.whl.metadata\n  Downloading jupyterlab_widgets-3.0.10-py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: backcall in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.0)\nRequirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\nRequirement already satisfied: pickleshare in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.39)\nRequirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.16.1)\nRequirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\nRequirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\nRequirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\nRequirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\nDownloading ipywidgets-8.1.2-py3-none-any.whl (139 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n\u001b[?25hDownloading jupyterlab_widgets-3.0.10-py3-none-any.whl (215 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m215.0/215.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading widgetsnbextension-4.0.10-py3-none-any.whl (2.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\n  Attempting uninstall: widgetsnbextension\n    Found existing installation: widgetsnbextension 3.6.6\n    Uninstalling widgetsnbextension-3.6.6:\n      Successfully uninstalled widgetsnbextension-3.6.6\n  Attempting uninstall: jupyterlab-widgets\n    Found existing installation: jupyterlab-widgets 3.0.8\n    Uninstalling jupyterlab-widgets-3.0.8:\n      Successfully uninstalled jupyterlab-widgets-3.0.8\n  Attempting uninstall: ipywidgets\n    Found existing installation: ipywidgets 7.7.1\n    Uninstalling ipywidgets-7.7.1:\n      Successfully uninstalled ipywidgets-7.7.1\nSuccessfully installed ipywidgets-8.1.2 jupyterlab-widgets-3.0.10 widgetsnbextension-4.0.10\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Set tensorboard or comet for monitoring","metadata":{}},{"cell_type":"code","source":"logger = 'Comet' #@param ['Comet', 'TensorBoard']\n\ncomet_key = '053dXzGWtieRxHSx26aTnUTCC'\n\nif logger == 'Comet':\n  %pip install -q comet_ml\n  import comet_ml; comet_ml.init()\nelif logger == 'TensorBoard':\n  %load_ext tensorboard\n  %tensorboard --logdir /content/runs/detect/train","metadata":{"execution":{"iopub.status.busy":"2024-02-17T12:25:57.519265Z","iopub.execute_input":"2024-02-17T12:25:57.519950Z","iopub.status.idle":"2024-02-17T12:26:15.102496Z","shell.execute_reply.started":"2024-02-17T12:25:57.519916Z","shell.execute_reply":"2024-02-17T12:26:15.101538Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\njupyterlab 4.0.10 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\nPlease paste your Comet API key from https://www.comet.com/api/my/settings/\n(api key may not show as you type)\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Comet API key:  Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"},{"name":"stderr","text":"\u001b[1;38;5;39mCOMET INFO:\u001b[0m Valid Comet API Key saved in /root/.comet.config (set COMET_CONFIG to change where it is saved).\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Set wand for monitoring","metadata":{}},{"cell_type":"code","source":"import wandb\n\nwandb.login(key='36ee4712b2b266eaa23e05b4d07f16fbee9f5a1e')","metadata":{"execution":{"iopub.status.busy":"2024-02-17T12:26:15.104151Z","iopub.execute_input":"2024-02-17T12:26:15.104462Z","iopub.status.idle":"2024-02-17T12:26:17.197143Z","shell.execute_reply.started":"2024-02-17T12:26:15.104434Z","shell.execute_reply":"2024-02-17T12:26:17.196279Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"markdown","source":"### Clear 'runs' directories","metadata":{}},{"cell_type":"code","source":"!rm -r runs\n# !rm -r results","metadata":{"execution":{"iopub.status.busy":"2024-02-17T14:09:07.052178Z","iopub.execute_input":"2024-02-17T14:09:07.052657Z","iopub.status.idle":"2024-02-17T14:09:08.095200Z","shell.execute_reply.started":"2024-02-17T14:09:07.052618Z","shell.execute_reply":"2024-02-17T14:09:08.093934Z"},"trusted":true},"execution_count":96,"outputs":[{"name":"stdout","text":"rm: cannot remove 'runs': No such file or directory\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Train yolo model","metadata":{}},{"cell_type":"code","source":"from ultralytics import YOLO\n\n# Load a model\nmodel = YOLO('models/yolov8n-cls.pt')  # load a pretrained model (recommended for training)\n\n# Define train parameters\nparams = {\n    'data': '../input/flood-imbalanced-train/imbalanced_train',\n#     'data': '../input/flood-balanced-train/balanced_train',\n    'epochs': 300,\n    'imgsz': 640,  # default 640\n    'batch': 64,  # default 16\n    'device': [0, 1],\n    'patience': 5,\n#     'plots': True,\n#     'multi_scale': True,\n#     'optimizer': 'AdamW',\n#     'lr0': 1e-9,\n#     'lrf': 1e-9,  # default: 0.01\n#     'momentum': 0.8,  # default: 0.937\n#     'warmup_epochs': 8.0,\n#     'augment': True,\n#     'single_cls': True,\n#     'label_smoothing': 0.0\n}\n\n# Train the model\nresults = model.train(**params)","metadata":{"execution":{"iopub.status.busy":"2024-02-17T14:09:17.324043Z","iopub.execute_input":"2024-02-17T14:09:17.324865Z","iopub.status.idle":"2024-02-17T14:20:43.069964Z","shell.execute_reply.started":"2024-02-17T14:09:17.324827Z","shell.execute_reply":"2024-02-17T14:20:43.069077Z"},"trusted":true},"execution_count":97,"outputs":[{"name":"stdout","text":"Ultralytics YOLOv8.1.14 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15102MiB)\n                                                      CUDA:1 (Tesla T4, 15102MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=models/yolov8n-cls.pt, data=../input/flood-imbalanced-train/imbalanced_train, epochs=300, time=None, patience=5, batch=64, imgsz=640, save=True, save_period=-1, cache=False, device=[0, 1], workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/train\n\u001b[34m\u001b[1mtrain:\u001b[0m /kaggle/input/flood-imbalanced-train/imbalanced_train/train... found 4009 images in 2 classes âœ… \n\u001b[34m\u001b[1mval:\u001b[0m /kaggle/input/flood-imbalanced-train/imbalanced_train/val... found 345 images in 2 classes âœ… \n\u001b[34m\u001b[1mtest:\u001b[0m /kaggle/input/flood-imbalanced-train/imbalanced_train/test... found 360 images in 2 classes âœ… \nOverriding model.yaml nc=1000 with nc=2\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    332802  ultralytics.nn.modules.head.Classify         [256, 2]                      \nYOLOv8n-cls summary: 99 layers, 1440850 parameters, 1440850 gradients, 3.4 GFLOPs\nTransferred 156/158 items from pretrained weights\n\u001b[34m\u001b[1mDDP:\u001b[0m debug command /opt/conda/bin/python3.10 -m torch.distributed.run --nproc_per_node 2 --master_port 35411 /root/.config/Ultralytics/DDP/_temp_j6gcjocj134365717027408.py\nUltralytics YOLOv8.1.14 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15102MiB)\n                                                      CUDA:1 (Tesla T4, 15102MiB)\n\u001b[34m\u001b[1mtrain:\u001b[0m /kaggle/input/flood-imbalanced-train/imbalanced_train/train... found 4009 images in 2 classes âœ… \n\u001b[34m\u001b[1mval:\u001b[0m /kaggle/input/flood-imbalanced-train/imbalanced_train/val... found 345 images in 2 classes âœ… \n\u001b[34m\u001b[1mtest:\u001b[0m /kaggle/input/flood-imbalanced-train/imbalanced_train/test... found 360 images in 2 classes âœ… \n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/kaggle/working' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com \u001b[38;5;39mhttps://www.comet.com/luisresende13/general/1b27b1c454b846f6bf29425fb24e53ed\u001b[0m\n\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/classify/train', view at http://localhost:6006/\n","output_type":"stream"},{"name":"stderr","text":"wandb: Currently logged in as: luisresende13 (octacity). Use `wandb login --relogin` to force relogin\nwandb: wandb version 0.16.3 is available!  To upgrade, please run:\nwandb:  $ pip install wandb --upgrade\nwandb: Tracking run with wandb version 0.16.2\nwandb: Run data is saved locally in /kaggle/working/wandb/run-20240217_140935-y4bkrkyu\nwandb: Run `wandb offline` to turn off syncing.\nwandb: Syncing run train\nwandb: â­ï¸ View project at https://wandb.ai/octacity/YOLOv8\nwandb: ðŸš€ View run at https://wandb.ai/octacity/YOLOv8/runs/y4bkrkyu\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/flood-imbalanced-train/imbalanced_train/train... 4009 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4009/4009 [00:03<00:00, 1238.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ Cache directory /kaggle/input/flood-imbalanced-train/imbalanced_train is not writeable, cache not saved.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/flood-imbalanced-train/imbalanced_train/val... 345 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 345/345 [00:00<00:00, 852.77it/s]9it/s]\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/flood-imbalanced-train/imbalanced_train/train... 831 images, 0 corrupt:  21%|â–ˆâ–ˆ        | 831/4009 [00:00<00:02, 1490.83it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ Cache directory /kaggle/input/flood-imbalanced-train/imbalanced_train is not writeable, cache not saved.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/flood-imbalanced-train/imbalanced_train/train... 1197 images, 0 corrupt:  30%|â–ˆâ–ˆâ–‰       | 1197/4009 [00:00<00:01, 1601.45it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/flood-imbalanced-train/imbalanced_train/train... 4009 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4009/4009 [00:02<00:00, 1723.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/classify/train\u001b[0m\nStarting training for 300 epochs...\n\n      Epoch    GPU_mem       loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      1/300      3.24G     0.7288         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [01:39<00:00,  1.59s/it]\n               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:03<00:00,  1.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      0.522          1\n\n      Epoch    GPU_mem       loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      2/300      2.85G     0.5064         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [01:08<00:00,  1.08s/it]\n               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      0.667          1\n\n      Epoch    GPU_mem       loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      3/300      2.85G     0.3254         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [01:06<00:00,  1.06s/it]\n               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       0.69          1\n\n      Epoch    GPU_mem       loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      4/300      2.85G     0.2008         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [01:05<00:00,  1.04s/it]\n               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      0.571          1\n\n      Epoch    GPU_mem       loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      5/300      2.85G     0.1642         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [01:06<00:00,  1.06s/it]\n               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      0.623          1\n\n      Epoch    GPU_mem       loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      6/300      2.85G     0.1156         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [01:06<00:00,  1.06s/it]\n               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      0.635          1\n\n      Epoch    GPU_mem       loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      7/300      2.85G     0.1199         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [01:06<00:00,  1.06s/it]\n               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      0.557          1\n\n      Epoch    GPU_mem       loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      8/300      2.85G     0.1108         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [01:06<00:00,  1.06s/it]\n               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      0.626          1\nStopping training early as no improvement observed in last 5 epochs. Best results observed at epoch 3, best model saved as best.pt.\nTo update EarlyStopping(patience=5) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n\n8 epochs completed in 0.169 hours.\nOptimizer stripped from runs/classify/train/weights/last.pt, 3.0MB\nOptimizer stripped from runs/classify/train/weights/best.pt, 3.0MB\n\nValidating runs/classify/train/weights/best.pt...\nUltralytics YOLOv8.1.14 ðŸš€ Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15102MiB)\nYOLOv8n-cls summary (fused): 73 layers, 1437442 parameters, 0 gradients, 3.3 GFLOPs\n\u001b[34m\u001b[1mtrain:\u001b[0m /kaggle/input/flood-imbalanced-train/imbalanced_train/train... found 4009 images in 2 classes âœ… \n\u001b[34m\u001b[1mval:\u001b[0m /kaggle/input/flood-imbalanced-train/imbalanced_train/val... found 345 images in 2 classes âœ… \n\u001b[34m\u001b[1mtest:\u001b[0m /kaggle/input/flood-imbalanced-train/imbalanced_train/test... found 360 images in 2 classes âœ… \n","output_type":"stream"},{"name":"stderr","text":"               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:05<00:00,  1.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       0.69          1\nSpeed: 1.1ms preprocess, 1.6ms inference, 0.0ms loss, 0.0ms postprocess per image\nResults saved to \u001b[1mruns/classify/train\u001b[0m\nResults saved to \u001b[1mruns/classify/train\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"\u001b[1;38;5;196mCOMET ERROR:\u001b[0m We failed to read file runs/classify/train/F1_curve.png for uploading.\nPlease double-check the file path and permissions\n\u001b[1;38;5;196mCOMET ERROR:\u001b[0m We failed to read file runs/classify/train/P_curve.png for uploading.\nPlease double-check the file path and permissions\n\u001b[1;38;5;196mCOMET ERROR:\u001b[0m We failed to read file runs/classify/train/R_curve.png for uploading.\nPlease double-check the file path and permissions\n\u001b[1;38;5;196mCOMET ERROR:\u001b[0m We failed to read file runs/classify/train/PR_curve.png for uploading.\nPlease double-check the file path and permissions\n\u001b[1;38;5;196mCOMET ERROR:\u001b[0m We failed to read file runs/classify/train/labels.jpg for uploading.\nPlease double-check the file path and permissions\n\u001b[1;38;5;196mCOMET ERROR:\u001b[0m We failed to read file runs/classify/train/labels_correlogram.jpg for uploading.\nPlease double-check the file path and permissions\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : \u001b[38;5;39mhttps://www.comet.com/luisresende13/general/1b27b1c454b846f6bf29425fb24e53ed\u001b[0m\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg0 [17]                : (0.0032804232804232807, 0.009901)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg1 [17]                : (0.0032804232804232807, 0.009901)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg2 [17]                : (0.0032804232804232807, 0.009901)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/accuracy_top1 [18] : (0.52174, 0.68986)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/accuracy_top5      : 1.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/GFLOPs               : 3.362\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/parameters           : 1440850\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/speed_PyTorch(ms)    : 1.839\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/loss [16]            : (0.11081, 0.72885)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/loss [16]              : (0.61947, 0.7255)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_batch_logging_interval  : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_confusion_matrix_on_eval : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_image_predictions        : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_image_predictions        : 100\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     agnostic_nms    : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     amp             : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     augment         : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     auto_augment    : randaugment\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch           : 64\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     box             : 7.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cache           : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cfg             : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     classes         : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     close_mosaic    : 10\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls             : 0.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conf            : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste      : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cos_lr          : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     crop_fraction   : 1.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     data            : ../input/flood-imbalanced-train/imbalanced_train\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     degrees         : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     deterministic   : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     device          : [0, 1]\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dfl             : 1.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dnn             : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout         : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dynamic         : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     embed           : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epochs          : 300\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     erasing         : 0.4\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     exist_ok        : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fliplr          : 0.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flipud          : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     format          : torchscript\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fraction        : 1.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     freeze          : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     half            : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_h           : 0.015\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_s           : 0.7\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_v           : 0.4\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imgsz           : 640\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     int8            : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     iou             : 0.7\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     keras           : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     kobj            : 1.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     label_smoothing : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     line_width      : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr0             : 0.01\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lrf             : 0.01\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mask_ratio      : 4\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_det         : 300\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mixup           : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mode            : train\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model           : models/yolov8n-cls.pt\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum        : 0.937\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mosaic          : 1.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     multi_scale     : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name            : train\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nbs             : 64\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nms             : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     opset           : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimize        : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer       : auto\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     overlap_mask    : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     patience        : 5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     perspective     : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     plots           : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pose            : 12.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pretrained      : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     profile         : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project         : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rect            : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume          : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     retina_masks    : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save            : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_conf       : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_crop       : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_dir        : runs/classify/train\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_frames     : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_hybrid     : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_json       : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_period     : -1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_txt        : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     scale           : 0.5\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed            : 0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     shear           : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show            : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_boxes      : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_conf       : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_labels     : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     simplify        : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     single_cls      : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source          : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     split           : val\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     stream_buffer   : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     task            : classify\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     time            : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tracker         : botsort.yaml\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     translate       : 0.1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val             : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     verbose         : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vid_stride      : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualize       : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_bias_lr  : 0.1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_epochs   : 3.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_momentum : 0.8\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weight_decay    : 0.0005\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workers         : 8\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workspace       : 4\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-environment-definition : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-info                   : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-specification          : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     confusion-matrix             : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details          : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                     : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images                       : 4\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages           : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element                : 1 (2.83 MB)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages                  : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code                  : 2 (15.72 KB)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for metadata to finish uploading (timeout is 3600 seconds)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Uploading 123 metrics, params and output messages\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n# Specify the path to your image\nimage_path = \"runs/classify/train/F1_curve.png\"\n\n# Load the image using matplotlib's imread function\nimage = mpimg.imread(image_path)\n\n# Display the image\nplt.imshow(image)\nplt.axis('off')  # Turn off axis labels\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-17T14:23:15.287156Z","iopub.execute_input":"2024-02-17T14:23:15.288157Z","iopub.status.idle":"2024-02-17T14:23:15.357284Z","shell.execute_reply.started":"2024-02-17T14:23:15.288119Z","shell.execute_reply":"2024-02-17T14:23:15.356100Z"},"trusted":true},"execution_count":108,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[108], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruns/classify/train/F1_curve.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Load the image using matplotlib's imread function\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mmpimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Display the image\u001b[39;00m\n\u001b[1;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(image)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/image.py:1563\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fname, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(parse\u001b[38;5;241m.\u001b[39murlparse(fname)\u001b[38;5;241m.\u001b[39mscheme) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1557\u001b[0m     \u001b[38;5;66;03m# Pillow doesn't handle URLs directly.\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1559\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease open the URL for reading and pass the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult to Pillow, e.g. with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m``np.array(PIL.Image.open(urllib.request.urlopen(url)))``.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1562\u001b[0m         )\n\u001b[0;32m-> 1563\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mimg_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m image:\n\u001b[1;32m   1564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (_pil_png_to_float_array(image)\n\u001b[1;32m   1565\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(image, PIL\u001b[38;5;241m.\u001b[39mPngImagePlugin\u001b[38;5;241m.\u001b[39mPngImageFile) \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[1;32m   1566\u001b[0m             pil_to_array(image))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/PIL/ImageFile.py:105\u001b[0m, in \u001b[0;36mImageFile.__init__\u001b[0;34m(self, fp, filename)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecodermaxblock \u001b[38;5;241m=\u001b[39m MAXBLOCK\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_path(fp):\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;66;03m# filename\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;241m=\u001b[39m fp\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'runs/classify/train/F1_curve.png'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'runs/classify/train/F1_curve.png'","output_type":"error"}]},{"cell_type":"markdown","source":"### Zip and download results folder","metadata":{}},{"cell_type":"code","source":"import shutil\n\n#  Function to zip a folder\ndef zip_folder(folder_path, zip_filename):\n    # Create a zip file using shutil\n    shutil.make_archive(zip_filename.split('.zip')[0], 'zip', folder_path)\n\n    # Move the created zip file to the correct path\n    shutil.move(zip_filename.split('.zip')[0] + '.zip', zip_filename)\n\n\ntrain_index = ''\n\n# Path to the folder you want to zip\nfolder_path = f'runs/classify/train{train_index}'\n\n# Path to save the zip file\nzip_filename = 'results/sgkf-50-25-25-size-2024-rs-2.zip'\n\n# Zip the folder\nzip_folder(folder_path, zip_filename)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-17T14:20:43.072024Z","iopub.execute_input":"2024-02-17T14:20:43.072544Z","iopub.status.idle":"2024-02-17T14:20:43.610309Z","shell.execute_reply.started":"2024-02-17T14:20:43.072508Z","shell.execute_reply":"2024-02-17T14:20:43.609243Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"markdown","source":"### Unzip folder with results","metadata":{}},{"cell_type":"code","source":"import zipfile\nimport os\n\n# Function to unzip a zip file\ndef unzip_folder(zip_file_path, extracted_dir_path):\n    # Create the directory if it doesn't exist\n    os.makedirs(extracted_dir_path, exist_ok=True)\n\n    # Extract the contents of the zip file\n    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n        zip_ref.extractall(extracted_dir_path)\n\n    print(f\"Contents of {zip_file_path} have been successfully extracted to {extracted_dir_path}.\")\n\n\n# Specify the path to your zip file\nzip_file_path = 'results/n-2.zip'\n\ntrain_index = ''\n\n# Specify the directory where you want to extract the contents\nextracted_dir_path = f'runs/classify/train{train_index}'\n\n# Unzip the contents of the zip file\nunzip_folder(zip_file_path, extracted_dir_path)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Resume interrupted training","metadata":{}},{"cell_type":"code","source":"from ultralytics import YOLO\n\ntrain_index = ''\n\n# Path to yolo `runs/detect/train` folder\nfolder_path = f'runs/classify/train{train_index}'\n\n# Define train parameters\nparams = {\n    'data': '../input/flood-imbalanced-train/imbalanced-train',\n#     'data': '../input/flood-balanced-train/balanced_train',\n#     'data': '../input/flood-images-split/under-10058-StratifiedGroupKFold-5',\n    'epochs': 100,\n    'imgsz': 640,\n    'batch': 16,\n    'device': [0, 1],\n    'single_cls': False,\n    'label_smoothing': 0.0\n}\n\n\n# Load a model\nmodel = YOLO(f'{folder_path}/weights/last.pt')  # load a partially trained model\n\n# Resume training\nresults = model.train(**params, resume=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# Model Evaluation","metadata":{}},{"cell_type":"markdown","source":"### Utility functions","metadata":{}},{"cell_type":"code","source":"import os\nfrom sklearn.metrics import classification_report as cr\n\ndef list_nested_files(directory):\n    file_list = []\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            file_list.append(os.path.join(root, file))\n    return file_list\n\n\ndef get_prediction(results):\n    yhat = []\n    probs = []\n    for result in results:\n        pred = result.probs.top1\n        prob = result.probs.top1conf.item()\n        yhat.append(pred)\n        probs.append(prob)\n    return yhat, probs","metadata":{"execution":{"iopub.status.busy":"2024-02-17T14:20:43.611591Z","iopub.execute_input":"2024-02-17T14:20:43.611895Z","iopub.status.idle":"2024-02-17T14:20:43.619387Z","shell.execute_reply.started":"2024-02-17T14:20:43.611868Z","shell.execute_reply":"2024-02-17T14:20:43.618335Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"markdown","source":"### Load trained model","metadata":{}},{"cell_type":"code","source":"from ultralytics import YOLO\n\ntrain_index = ''\n\n# Path to the folder you want to zip\nfolder_path = f'runs/classify/train{train_index}'\n\n# Define eval parameters\nparams = {\n    'data': '../input/flood-imbalanced-train/imbalanced_train',\n#     'data': '../input/flood-balanced-train/balanced_train',\n    'imgsz': 640,\n    'batch': 16,\n    'device': [0, 1],\n#     'split': 'test',\n}\n\n# Load a model\nmodel = YOLO(f'{folder_path}/weights/best.pt')  # load a partially trained model\n","metadata":{"execution":{"iopub.status.busy":"2024-02-17T14:21:19.883053Z","iopub.execute_input":"2024-02-17T14:21:19.883869Z","iopub.status.idle":"2024-02-17T14:21:19.913120Z","shell.execute_reply.started":"2024-02-17T14:21:19.883832Z","shell.execute_reply":"2024-02-17T14:21:19.912251Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"markdown","source":"---\n## Balanced training evaluation","metadata":{}},{"cell_type":"markdown","source":"### Evaluate test set","metadata":{}},{"cell_type":"code","source":"# List directory file paths\ndirectory = f\"{params['data']}/test\"\npath_list = list_nested_files(directory)\ny_true = list(map(lambda path: float(path.split('/')[-2]), path_list))\ncodes = map(lambda path:int(path.split('/')[-1].split(' ')[0][4:]), path_list)\n\n# Make predictions\nresults = model(path_list, verbose=False, device=[0, 1])\ny_hat, probs = get_prediction(results)\n\n# Convert to pandas series\ny_hat = pd.Series(y_hat)\nprobs = pd.Series(probs)\n\n# Classification report\nprint(cr(y_true, y_hat))","metadata":{"execution":{"iopub.status.busy":"2024-02-17T14:05:42.769630Z","iopub.execute_input":"2024-02-17T14:05:42.770596Z","iopub.status.idle":"2024-02-17T14:05:55.833043Z","shell.execute_reply.started":"2024-02-17T14:05:42.770559Z","shell.execute_reply":"2024-02-17T14:05:55.831885Z"},"trusted":true},"execution_count":88,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n         0.0       0.95      0.55      0.70       180\n         1.0       0.68      0.97      0.80       180\n\n    accuracy                           0.76       360\n   macro avg       0.82      0.76      0.75       360\nweighted avg       0.82      0.76      0.75       360\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Evaluate validation set","metadata":{}},{"cell_type":"code","source":"# List directory file paths\ndirectory = f\"{params['data']}/val\"\npath_list = list_nested_files(directory)\ny_true = pd.Series(map(lambda path: float(path.split('/')[-2]), path_list))\ncodes = pd.Series(map(lambda path:int(path.split('/')[-1].split(' ')[0][4:]), path_list))\n\n# Make predictions\nresults = model(path_list, verbose=False)\ny_hat, probs = get_prediction(results)\n\n# Convert to pandas series\ny_hat = pd.Series(y_hat)\nprobs = pd.Series(probs)\n\n# Classification report\nprint(cr(y_true, y_hat))","metadata":{"execution":{"iopub.status.busy":"2024-02-17T14:05:55.835163Z","iopub.execute_input":"2024-02-17T14:05:55.835614Z","iopub.status.idle":"2024-02-17T14:06:05.295770Z","shell.execute_reply.started":"2024-02-17T14:05:55.835571Z","shell.execute_reply":"2024-02-17T14:06:05.294745Z"},"trusted":true},"execution_count":89,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n         0.0       0.74      0.64      0.68       180\n         1.0       0.66      0.75      0.70       165\n\n    accuracy                           0.69       345\n   macro avg       0.70      0.70      0.69       345\nweighted avg       0.70      0.69      0.69       345\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Evaluate test set per camera","metadata":{}},{"cell_type":"code","source":"# List directory file paths\ndirectory = f\"{params['data']}/test\"\npath_list = list_nested_files(directory)\ny_true = pd.Series(map(lambda path: float(path.split('/')[-2]), path_list))\ncodes = pd.Series(map(lambda path:int(path.split('/')[-1].split(' ')[0][4:]), path_list))\n\n# Make predictions\nresults = model(path_list, verbose=False)\ny_hat, probs = get_prediction(results)\n\n# Convert to pandas series\ny_hat = pd.Series(y_hat)\nprobs = pd.Series(probs)\n\n# Classification report per camera\nfor code in codes.unique():\n    msk = codes == code\n    print(f'\\nClassification Report (CODE {code}):\\n')\n    print(cr(y_true[msk], y_hat[msk]))","metadata":{"execution":{"iopub.status.busy":"2024-02-17T14:06:40.158624Z","iopub.execute_input":"2024-02-17T14:06:40.159002Z","iopub.status.idle":"2024-02-17T14:06:50.100807Z","shell.execute_reply.started":"2024-02-17T14:06:40.158963Z","shell.execute_reply":"2024-02-17T14:06:50.099660Z"},"trusted":true},"execution_count":92,"outputs":[{"name":"stdout","text":"\nClassification Report (CODE 310):\n\n              precision    recall  f1-score   support\n\n         0.0       1.00      0.50      0.67        30\n         1.0       0.67      1.00      0.80        30\n\n    accuracy                           0.75        60\n   macro avg       0.83      0.75      0.73        60\nweighted avg       0.83      0.75      0.73        60\n\n\nClassification Report (CODE 1881):\n\n              precision    recall  f1-score   support\n\n         0.0       1.00      0.10      0.18        30\n         1.0       0.53      1.00      0.69        30\n\n    accuracy                           0.55        60\n   macro avg       0.76      0.55      0.44        60\nweighted avg       0.76      0.55      0.44        60\n\n\nClassification Report (CODE 92):\n\n              precision    recall  f1-score   support\n\n         0.0       0.94      0.97      0.95        30\n         1.0       0.97      0.93      0.95        30\n\n    accuracy                           0.95        60\n   macro avg       0.95      0.95      0.95        60\nweighted avg       0.95      0.95      0.95        60\n\n\nClassification Report (CODE 1994):\n\n              precision    recall  f1-score   support\n\n         0.0       1.00      0.80      0.89        30\n         1.0       0.83      1.00      0.91        30\n\n    accuracy                           0.90        60\n   macro avg       0.92      0.90      0.90        60\nweighted avg       0.92      0.90      0.90        60\n\n\nClassification Report (CODE 339):\n\n              precision    recall  f1-score   support\n\n         0.0       0.90      0.60      0.72        30\n         1.0       0.70      0.93      0.80        30\n\n    accuracy                           0.77        60\n   macro avg       0.80      0.77      0.76        60\nweighted avg       0.80      0.77      0.76        60\n\n\nClassification Report (CODE 430):\n\n              precision    recall  f1-score   support\n\n         0.0       0.91      0.33      0.49        30\n         1.0       0.59      0.97      0.73        30\n\n    accuracy                           0.65        60\n   macro avg       0.75      0.65      0.61        60\nweighted avg       0.75      0.65      0.61        60\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Evaluate validation set per camera","metadata":{}},{"cell_type":"code","source":"# List directory file paths\ndirectory = f\"{params['data']}/val\"\npath_list = list_nested_files(directory)\ny_true = pd.Series(map(lambda path: float(path.split('/')[-2]), path_list))\ncodes = pd.Series(map(lambda path:int(path.split('/')[-1].split(' ')[0][4:]), path_list))\n\n# Make predictions\nresults = model(path_list, verbose=False)\ny_hat, probs = get_prediction(results)\n\n# Convert to pandas series\ny_hat = pd.Series(y_hat)\nprobs = pd.Series(probs)\n\n# Classification report per code\nfor code in codes.unique():\n    print(f'\\nClassification Report (CODE {code}):\\n')\n    msk = codes == code\n    print(cr(y_true[msk], y_hat[msk]))","metadata":{"execution":{"iopub.status.busy":"2024-02-17T14:07:05.842243Z","iopub.execute_input":"2024-02-17T14:07:05.843011Z","iopub.status.idle":"2024-02-17T14:07:15.353642Z","shell.execute_reply.started":"2024-02-17T14:07:05.842979Z","shell.execute_reply":"2024-02-17T14:07:15.352576Z"},"trusted":true},"execution_count":94,"outputs":[{"name":"stdout","text":"\nClassification Report (CODE 313):\n\n              precision    recall  f1-score   support\n\n         0.0       1.00      0.50      0.67        30\n         1.0       0.50      1.00      0.67        15\n\n    accuracy                           0.67        45\n   macro avg       0.75      0.75      0.67        45\nweighted avg       0.83      0.67      0.67        45\n\n\nClassification Report (CODE 38):\n\n              precision    recall  f1-score   support\n\n         0.0       1.00      0.03      0.06        30\n         1.0       0.51      1.00      0.67        30\n\n    accuracy                           0.52        60\n   macro avg       0.75      0.52      0.37        60\nweighted avg       0.75      0.52      0.37        60\n\n\nClassification Report (CODE 1147):\n\n              precision    recall  f1-score   support\n\n         0.0       0.50      1.00      0.67        30\n         1.0       0.00      0.00      0.00        30\n\n    accuracy                           0.50        60\n   macro avg       0.25      0.50      0.33        60\nweighted avg       0.25      0.50      0.33        60\n\n\nClassification Report (CODE 94):\n\n              precision    recall  f1-score   support\n\n         0.0       0.96      0.73      0.83        30\n         1.0       0.78      0.97      0.87        30\n\n    accuracy                           0.85        60\n   macro avg       0.87      0.85      0.85        60\nweighted avg       0.87      0.85      0.85        60\n\n\nClassification Report (CODE 1538):\n\n              precision    recall  f1-score   support\n\n         0.0       0.70      0.77      0.73        30\n         1.0       0.74      0.67      0.70        30\n\n    accuracy                           0.72        60\n   macro avg       0.72      0.72      0.72        60\nweighted avg       0.72      0.72      0.72        60\n\n\nClassification Report (CODE 326):\n\n              precision    recall  f1-score   support\n\n         0.0       1.00      0.80      0.89        30\n         1.0       0.83      1.00      0.91        30\n\n    accuracy                           0.90        60\n   macro avg       0.92      0.90      0.90        60\nweighted avg       0.92      0.90      0.90        60\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"markdown","source":"---\n## Imbalanced training evaluation","metadata":{}},{"cell_type":"markdown","source":"#### Evaluate test set","metadata":{}},{"cell_type":"code","source":"# List directory file paths\ndirectory = f\"{params['data']}/test\"\npath_list = list_nested_files(directory)\ny_true = list(map(lambda path: float(path.split('/')[-2]), path_list))\ncodes = map(lambda path:int(path.split('/')[-1].split(' ')[0][4:]), path_list)\n\n# Make predictions\nresults = model(path_list, verbose=False, device=[0, 1])\ny_hat, probs = get_prediction(results)\n\n# Convert to pandas series\ny_hat = pd.Series(y_hat)\nprobs = pd.Series(probs)\n\n# Classification report\nprint(cr(y_true, y_hat))","metadata":{"execution":{"iopub.status.busy":"2024-02-17T14:21:26.044409Z","iopub.execute_input":"2024-02-17T14:21:26.044968Z","iopub.status.idle":"2024-02-17T14:21:37.224439Z","shell.execute_reply.started":"2024-02-17T14:21:26.044907Z","shell.execute_reply":"2024-02-17T14:21:37.223225Z"},"trusted":true},"execution_count":103,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n         0.0       0.74      0.89      0.81       180\n         1.0       0.86      0.68      0.76       180\n\n    accuracy                           0.79       360\n   macro avg       0.80      0.79      0.78       360\nweighted avg       0.80      0.79      0.78       360\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Evaluate validation set","metadata":{}},{"cell_type":"code","source":"# List directory file paths\ndirectory = f\"{params['data']}/val\"\npath_list = list_nested_files(directory)\ny_true = pd.Series(map(lambda path: float(path.split('/')[-2]), path_list))\ncodes = pd.Series(map(lambda path:int(path.split('/')[-1].split(' ')[0][4:]), path_list))\n\n# Make predictions\nresults = model(path_list, verbose=False)\ny_hat, probs = get_prediction(results)\n\n# Convert to pandas series\ny_hat = pd.Series(y_hat)\nprobs = pd.Series(probs)\n\n# Classification report\nprint(cr(y_true, y_hat))","metadata":{"execution":{"iopub.status.busy":"2024-02-17T14:21:37.226993Z","iopub.execute_input":"2024-02-17T14:21:37.227335Z","iopub.status.idle":"2024-02-17T14:21:46.809997Z","shell.execute_reply.started":"2024-02-17T14:21:37.227305Z","shell.execute_reply":"2024-02-17T14:21:46.809024Z"},"trusted":true},"execution_count":104,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n         0.0       0.64      0.94      0.76       180\n         1.0       0.87      0.41      0.56       165\n\n    accuracy                           0.69       345\n   macro avg       0.75      0.68      0.66       345\nweighted avg       0.75      0.69      0.66       345\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Evaluate test set per camera","metadata":{}},{"cell_type":"code","source":"# List directory file paths\ndirectory = f\"{params['data']}/test\"\npath_list = list_nested_files(directory)\ny_true = pd.Series(map(lambda path: float(path.split('/')[-2]), path_list))\ncodes = pd.Series(map(lambda path:int(path.split('/')[-1].split(' ')[0][4:]), path_list))\n\n# Make predictions\nresults = model(path_list, verbose=False)\ny_hat, probs = get_prediction(results)\n\n# Convert to pandas series\ny_hat = pd.Series(y_hat)\nprobs = pd.Series(probs)\n\n# Classification report per camera\nfor code in codes.unique():\n    msk = codes == code\n    print(f'\\nClassification Report (CODE {code}):\\n')\n    print(cr(y_true[msk], y_hat[msk]))","metadata":{"execution":{"iopub.status.busy":"2024-02-17T14:21:46.811497Z","iopub.execute_input":"2024-02-17T14:21:46.811897Z","iopub.status.idle":"2024-02-17T14:21:57.012548Z","shell.execute_reply.started":"2024-02-17T14:21:46.811861Z","shell.execute_reply":"2024-02-17T14:21:57.011437Z"},"trusted":true},"execution_count":105,"outputs":[{"name":"stdout","text":"\nClassification Report (CODE 310):\n\n              precision    recall  f1-score   support\n\n         0.0       0.88      0.97      0.92        30\n         1.0       0.96      0.87      0.91        30\n\n    accuracy                           0.92        60\n   macro avg       0.92      0.92      0.92        60\nweighted avg       0.92      0.92      0.92        60\n\n\nClassification Report (CODE 1881):\n\n              precision    recall  f1-score   support\n\n         0.0       0.88      0.77      0.82        30\n         1.0       0.79      0.90      0.84        30\n\n    accuracy                           0.83        60\n   macro avg       0.84      0.83      0.83        60\nweighted avg       0.84      0.83      0.83        60\n\n\nClassification Report (CODE 92):\n\n              precision    recall  f1-score   support\n\n         0.0       0.61      1.00      0.76        30\n         1.0       1.00      0.37      0.54        30\n\n    accuracy                           0.68        60\n   macro avg       0.81      0.68      0.65        60\nweighted avg       0.81      0.68      0.65        60\n\n\nClassification Report (CODE 1994):\n\n              precision    recall  f1-score   support\n\n         0.0       0.88      1.00      0.94        30\n         1.0       1.00      0.87      0.93        30\n\n    accuracy                           0.93        60\n   macro avg       0.94      0.93      0.93        60\nweighted avg       0.94      0.93      0.93        60\n\n\nClassification Report (CODE 339):\n\n              precision    recall  f1-score   support\n\n         0.0       0.62      0.87      0.72        30\n         1.0       0.78      0.47      0.58        30\n\n    accuracy                           0.67        60\n   macro avg       0.70      0.67      0.65        60\nweighted avg       0.70      0.67      0.65        60\n\n\nClassification Report (CODE 430):\n\n              precision    recall  f1-score   support\n\n         0.0       0.67      0.73      0.70        30\n         1.0       0.70      0.63      0.67        30\n\n    accuracy                           0.68        60\n   macro avg       0.69      0.68      0.68        60\nweighted avg       0.69      0.68      0.68        60\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Evaluate validation set per camera","metadata":{}},{"cell_type":"code","source":"# List directory file paths\ndirectory = f\"{params['data']}/val\"\npath_list = list_nested_files(directory)\ny_true = pd.Series(map(lambda path: float(path.split('/')[-2]), path_list))\ncodes = pd.Series(map(lambda path:int(path.split('/')[-1].split(' ')[0][4:]), path_list))\n\n# Make predictions\nresults = model(path_list, verbose=False)\ny_hat, probs = get_prediction(results)\n\n# Convert to pandas series\ny_hat = pd.Series(y_hat)\nprobs = pd.Series(probs)\n\n\n# Classification report per code\nfor code in codes.unique():\n    msk = codes == code\n    print(f'\\nClassification Report (CODE {code}):\\n')\n    print(cr(y_true[msk], y_hat[msk]))","metadata":{"execution":{"iopub.status.busy":"2024-02-17T14:21:57.015042Z","iopub.execute_input":"2024-02-17T14:21:57.015777Z","iopub.status.idle":"2024-02-17T14:22:06.688274Z","shell.execute_reply.started":"2024-02-17T14:21:57.015734Z","shell.execute_reply":"2024-02-17T14:22:06.687220Z"},"trusted":true},"execution_count":106,"outputs":[{"name":"stdout","text":"\nClassification Report (CODE 313):\n\n              precision    recall  f1-score   support\n\n         0.0       0.94      1.00      0.97        30\n         1.0       1.00      0.87      0.93        15\n\n    accuracy                           0.96        45\n   macro avg       0.97      0.93      0.95        45\nweighted avg       0.96      0.96      0.95        45\n\n\nClassification Report (CODE 38):\n\n              precision    recall  f1-score   support\n\n         0.0       0.56      0.80      0.66        30\n         1.0       0.65      0.37      0.47        30\n\n    accuracy                           0.58        60\n   macro avg       0.60      0.58      0.56        60\nweighted avg       0.60      0.58      0.56        60\n\n\nClassification Report (CODE 1147):\n\n              precision    recall  f1-score   support\n\n         0.0       0.50      1.00      0.67        30\n         1.0       0.00      0.00      0.00        30\n\n    accuracy                           0.50        60\n   macro avg       0.25      0.50      0.33        60\nweighted avg       0.25      0.50      0.33        60\n\n\nClassification Report (CODE 94):\n\n              precision    recall  f1-score   support\n\n         0.0       0.79      0.87      0.83        30\n         1.0       0.85      0.77      0.81        30\n\n    accuracy                           0.82        60\n   macro avg       0.82      0.82      0.82        60\nweighted avg       0.82      0.82      0.82        60\n\n\nClassification Report (CODE 1538):\n\n              precision    recall  f1-score   support\n\n         0.0       0.50      1.00      0.67        30\n         1.0       0.00      0.00      0.00        30\n\n    accuracy                           0.50        60\n   macro avg       0.25      0.50      0.33        60\nweighted avg       0.25      0.50      0.33        60\n\n\nClassification Report (CODE 326):\n\n              precision    recall  f1-score   support\n\n         0.0       0.77      1.00      0.87        30\n         1.0       1.00      0.70      0.82        30\n\n    accuracy                           0.85        60\n   macro avg       0.88      0.85      0.85        60\nweighted avg       0.88      0.85      0.85        60\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]}]}