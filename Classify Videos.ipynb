{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4eccf1eb-e642-45dc-b45f-bb0097d1e804",
   "metadata": {},
   "source": [
    "#### Reload images and videos datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dc1797b-f399-45de-899c-24ebfb834d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['_id', 'blob_name', 'blob_size', 'bucket_name', 'file_name', 'code',\n",
      "       'n_folders', 'timestamp', 'folder_structure', 'folder', 'tags', 'url',\n",
      "       'api_url', 'bucket', 'seen'],\n",
      "      dtype='object')\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=10, step=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "df_images = pd.read_csv('data/datasets/images.csv')\n",
    "df_videos = pd.read_csv('data/datasets/videos.csv')\n",
    "\n",
    "# df_images['tags'] = df_images['tags'].apply(json.loads)\n",
    "df_videos['tags'] = df_videos['tags'].apply(json.loads)\n",
    "\n",
    "print(df_videos.columns)\n",
    "print()\n",
    "display(df_videos.index[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027136bd-1148-46e5-8076-15cba484525c",
   "metadata": {},
   "source": [
    "#### Create tag field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "589f97e0-2039-465d-b7ad-e0fc1e7564f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag\n",
       "normal        59695\n",
       "poça           1744\n",
       "bolsão          277\n",
       "lâmina          153\n",
       "alagamento       86\n",
       "transbordo       62\n",
       "Name: Videos, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tag\n",
       "normal        154843\n",
       "poça           69839\n",
       "bolsão         10621\n",
       "lâmina          5218\n",
       "alagamento      5026\n",
       "transbordo      2237\n",
       "Name: Images, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from modules.octa_video_util import _assign_tag\n",
    "\n",
    "# Create unique tag column based on class priority list\n",
    "default_tag = 'normal'\n",
    "tags_priority_list = ['alagamento', 'bolsão', 'lâmina', 'poça', 'transbordo']\n",
    "\n",
    "df_videos['tag'] = df_videos['tags'].apply(lambda tags_list: _assign_tag(tags_list, tags_priority_list, default_tag))\n",
    "df_images['tag'] = df_images['tags'].apply(lambda tags_list: _assign_tag(tags_list, tags_priority_list, default_tag))\n",
    "\n",
    "display(df_videos.tag.value_counts().rename('Videos'))\n",
    "print()\n",
    "display(df_images.tag.value_counts().rename('Images'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4116e83a-5d9b-4b84-8892-5e776eaf25b1",
   "metadata": {},
   "source": [
    "#### Binarize 'tag' variable for images dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "954d1006-7d56-4abf-b2bd-b008f59bb7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flood\n",
       "0    226919\n",
       "1     20865\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=10, step=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_classes = ['lâmina', 'bolsão', 'alagamento']\n",
    "\n",
    "# Binarize categorical variable from list of target classes\n",
    "df_images['flood'] = df_images['tag'].isin(target_classes).astype(int)\n",
    "\n",
    "display(df_images['flood'].value_counts())\n",
    "print()\n",
    "display(df_images.index[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502a59c7-0be8-4fd6-bbca-c79c5c917c6b",
   "metadata": {},
   "source": [
    "#### Filter videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2722dd04-8381-4899-81e9-9c2f443bd86b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag\n",
       "normal        4089\n",
       "poça          1743\n",
       "bolsão         275\n",
       "lâmina         152\n",
       "alagamento      85\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype='int64')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from modules.octa_video_util import filter_by_query\n",
    "\n",
    "query_params = {\n",
    "    'seen': True,\n",
    "    'tag': ['normal', 'poça', 'lâmina', 'bolsão', 'alagamento']\n",
    "}\n",
    "\n",
    "# Filter dataset of images by query\n",
    "df_videos_filtered = filter_by_query(df_videos, query_params).copy()\n",
    "\n",
    "display(df_videos_filtered['tag'].value_counts())\n",
    "print()\n",
    "display(df_videos_filtered.index[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a04a2b-8498-4902-9820-f9221eab2a98",
   "metadata": {},
   "source": [
    "#### Reload sample images dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d041d226-ae47-470b-8d0f-21b09c9c370b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id_video', 'code', 'folder', 'file_name', 'file_path', 'frame_index',\n",
      "       'timestamp', 'initial_timestamp', 'seen', 'tags', 'tag', 'flood',\n",
      "       'set'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index([106170, 173236, 223883, 223535, 180913, 177444, 75080, 127184, 173623,\n",
       "       225050],\n",
       "      dtype='int64')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# target_directory = 'data/splits/sgkf-8-1-1'\n",
    "target_directory = 'data/splits/sgkf-6-2-2-size-2024-rs-3'\n",
    "\n",
    "df_sample = pd.read_csv(f'{target_directory}/images.csv', index_col=0)\n",
    "\n",
    "print(df_sample.columns)\n",
    "display(df_sample.index[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4715832-9428-46f7-a86c-3f4f6c725577",
   "metadata": {},
   "source": [
    "#### Unique cameras in each data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52459e53-ed82-4ddc-992c-323f1316113b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train codes: 18\n",
      "Test codes: 6\n",
      "Val codes: 6\n",
      "Out-train codes: 182\n"
     ]
    }
   ],
   "source": [
    "train = df_sample[df_sample['set']=='train']\n",
    "test = df_sample[df_sample['set']=='test']\n",
    "val = df_sample[df_sample['set']=='val']\n",
    "\n",
    "train_codes = train['code'].unique()\n",
    "test_codes = test['code'].unique()\n",
    "val_codes = val['code'].unique()\n",
    "out_train_codes = set(df_videos_filtered['code'].unique()).difference(train_codes)\n",
    "\n",
    "print('Train codes:', len(train_codes))\n",
    "print('Test codes:', len(test_codes))\n",
    "print('Val codes:', len(val_codes))\n",
    "print('Out-train codes:', len(out_train_codes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562a1aa5-bb63-4286-930a-fb5b5b49e378",
   "metadata": {},
   "source": [
    "#### Test videos from cameras outside the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55c98ab9-38ee-4b9a-b8c3-60c7660e3b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag\n",
       "normal        3413\n",
       "poça          1490\n",
       "bolsão         221\n",
       "lâmina         111\n",
       "alagamento      47\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype='int64')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of sample for testing: (5282, 16)\n"
     ]
    }
   ],
   "source": [
    "df_videos_test = df_videos_filtered[~df_videos_filtered['code'].isin(train_codes)]\n",
    "\n",
    "display(df_videos_test['tag'].value_counts())\n",
    "print()\n",
    "display(df_videos_test.index[:10])\n",
    "print()\n",
    "print('Shape of sample for testing:', df_videos_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf2b806-9494-4ade-8d81-8b8fc08ade4a",
   "metadata": {},
   "source": [
    "#### Undersample videos based on flood event type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64ddf3e5-3da5-4aec-bfe7-e7937904bc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Videos selected: (20, 16)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tag\n",
       "bolsão        6\n",
       "normal        5\n",
       "poça          5\n",
       "lâmina        3\n",
       "alagamento    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>code</th>\n",
       "      <th>278.0</th>\n",
       "      <th>1538.0</th>\n",
       "      <th>298.0</th>\n",
       "      <th>97.0</th>\n",
       "      <th>1671.0</th>\n",
       "      <th>869.0</th>\n",
       "      <th>1460.0</th>\n",
       "      <th>1123.0</th>\n",
       "      <th>1639.0</th>\n",
       "      <th>2166.0</th>\n",
       "      <th>58.0</th>\n",
       "      <th>65.0</th>\n",
       "      <th>1649.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "code   278.0   1538.0  298.0   97.0    1671.0  869.0   1460.0  1123.0  1639.0  \\\n",
       "count       4       3       2       2       1       1       1       1       1   \n",
       "\n",
       "code   2166.0  58.0    65.0    1649.0  \n",
       "count       1       1       1       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index([29905, 40993, 40844, 40839, 37897, 25468, 42353, 24952, 32861, 24230], dtype='int64')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_majority_videos = 50\n",
    "n_minority_videos = 50\n",
    "random_state = 0\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "target_classes = ['lâmina', 'bolsão', 'alagamento']\n",
    "test_minority = df_videos_test[df_videos_test['tag'].isin(target_classes)]\n",
    "test_majority = df_videos_test.drop(test_minority.index)\n",
    "\n",
    "x = test_majority.copy()\n",
    "y = test_majority['tag'].copy()\n",
    "\n",
    "rus = RandomUnderSampler(sampling_strategy='auto', random_state=random_state, replacement=False)\n",
    "\n",
    "test_majority_filtered, tags_test_majority_filtered = rus.fit_resample(x, y)\n",
    "test_majority_filtered = test_majority_filtered.sample(n_majority_videos, replace=False, random_state=random_state)\n",
    "test_minority_filtered = test_minority.sample(n_minority_videos, replace=False, random_state=random_state)\n",
    "\n",
    "df_videos_test_filtered = pd.concat([test_minority_filtered, test_majority_filtered])\n",
    "\n",
    "print('Videos selected:', df_videos_test_filtered.shape)\n",
    "print()\n",
    "display(df_videos_test_filtered['tag'].value_counts())\n",
    "print()\n",
    "display(df_videos_test_filtered['code'].value_counts().to_frame().T)\n",
    "print()\n",
    "display(df_videos_test_filtered.index[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b423dc6-e17b-48b0-8cf6-af125cd518f6",
   "metadata": {},
   "source": [
    "#### Extract corresponding rows from images dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ef91a76-6fd1-4134-b620-87fb3743c874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images selected: (764, 12)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tag\n",
       "poça          225\n",
       "bolsão        200\n",
       "normal        159\n",
       "lâmina        135\n",
       "alagamento     45\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>code</th>\n",
       "      <th>1538.0</th>\n",
       "      <th>278.0</th>\n",
       "      <th>97.0</th>\n",
       "      <th>298.0</th>\n",
       "      <th>1123.0</th>\n",
       "      <th>58.0</th>\n",
       "      <th>1671.0</th>\n",
       "      <th>869.0</th>\n",
       "      <th>2166.0</th>\n",
       "      <th>1460.0</th>\n",
       "      <th>1639.0</th>\n",
       "      <th>1649.0</th>\n",
       "      <th>65.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>135</td>\n",
       "      <td>110</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "code   1538.0  278.0   97.0    298.0   1123.0  58.0    1671.0  869.0   2166.0  \\\n",
       "count     135     110      90      90      45      45      45      45      45   \n",
       "\n",
       "code   1460.0  1639.0  1649.0  65.0    \n",
       "count      45      45      17       7  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Videos found: 20\n"
     ]
    }
   ],
   "source": [
    "df_images_sample = df_images[df_images['id_video'].isin(df_videos_test_filtered['_id'])]\n",
    "\n",
    "print('Images selected:', df_images_sample.shape)\n",
    "print()\n",
    "display(df_images_sample['tag'].value_counts())\n",
    "print()\n",
    "display(df_images_sample['code'].value_counts().to_frame().T)\n",
    "print()\n",
    "print('Videos found:', len(df_images_sample['id_video'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9157967-75e6-43b9-b28b-60d2657409a0",
   "metadata": {},
   "source": [
    "#### Check existence of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a10b365-5d95-494d-adf6-ca3992d6a7ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'100.0 %'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def get_nested_files(folder_path):\n",
    "    file_paths = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            file_paths.append(file_path.replace('\\\\', '/'))\n",
    "    \n",
    "    return file_paths\n",
    "\n",
    "# Example usage\n",
    "# base_path = 'data/images'\n",
    "# images_paths_found = get_nested_files(base_path)\n",
    "\n",
    "\n",
    "base_path = 'data/images'\n",
    "\n",
    "images_paths_found = get_nested_files(base_path)\n",
    "images_paths_sample = df_images_sample['file_path'].apply(lambda file_path: f'{base_path}/{file_path}'.replace('\\\\', '/'))\n",
    "files_exist_prct = images_paths_sample.isin(images_paths_found).mean()\n",
    "\n",
    "str(round(files_exist_prct * 100, 2)) + ' %'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ea2c61-d507-4476-aad8-1d9ac562f9ac",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1ece11-7794-4fd6-8e22-2f9e5ce66910",
   "metadata": {},
   "source": [
    "## Run predictions with YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6313acba-ab11-4d68-9772-ce78eef3720a",
   "metadata": {},
   "source": [
    "#### Load model with Yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdb3573f-4e8d-46d8-8f47-90934f0bd131",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Path to the folder you want to zip\n",
    "# model_path = f'models/sgkf-8-1-1/weights/best.pt'\n",
    "model_path = f'models/sgkf-50-25-25-size-2024-rs-2/weights/best.pt'\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(model_path)  # load a partially trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92aa45a4-3f99-498d-b4ea-72db58e76bea",
   "metadata": {},
   "source": [
    "#### Run predictions with yolo in batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcda6d5d-6673-4efb-816b-4b44e4a66ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15540/15543 | 172.36 min / 172.4 min | time-left: 0.03 min\n",
      "\n",
      "0: 640x640 0 0.94, 1 0.06, 1: 640x640 0 0.89, 1 0.11, 2: 640x640 0 0.89, 1 0.11, 2212.3ms\n",
      "Speed: 45.0ms preprocess, 737.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from IPython.display import clear_output as co\n",
    "import time\n",
    "\n",
    "base_path = 'data/images'\n",
    "batch = 12\n",
    "\n",
    "eval_imgs_df = df_images_sample.sort_values(['id_video', 'frame_index'])# .head(45)\n",
    "img_path_list = f'{base_path}/' + eval_imgs_df['file_path']\n",
    "n_imgs = len(img_path_list)\n",
    "\n",
    "preds = []\n",
    "avg_time = 0.0\n",
    "s_time = time.time()\n",
    "for i in range(0, n_imgs, batch):\n",
    "    e_time = time.time() - s_time\n",
    "    e_time_round = round(e_time / 60, 2)\n",
    "    avg_time = e_time / max(1, i)\n",
    "    expected_finish_time = round((n_imgs - i) * avg_time / 60, 2)\n",
    "    expected_total_time = round(n_imgs * avg_time  / 60, 2)\n",
    "\n",
    "    co(True)\n",
    "    print(f'{i}/{n_imgs} | {e_time_round} min / {expected_total_time} min | time-left: {expected_finish_time} min')    \n",
    "\n",
    "    img_path_list_batch = img_path_list[i: i + batch].tolist()\n",
    "    pred = model.predict(img_path_list_batch, imgsz=640)\n",
    "    pred = [[pred_i.probs.data[1].item(), pred_i.probs.top1] for pred_i in pred]\n",
    "    preds.extend(pred)\n",
    "\n",
    "eval_imgs_df[['prob', 'pred']] = preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659c9cda-daa9-46f6-aa32-9359e941357e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1b9905-f8e9-4f67-a558-fee6b7c4ea88",
   "metadata": {},
   "source": [
    "## Run predictions with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c1ba1e-1d48-4adf-99a6-41e2ebb16396",
   "metadata": {},
   "source": [
    "#### Load model with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a9b095e-6876-42ca-b87c-e33e685d2bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All parameters for model VisionTransformer requires grad.\n",
      "Weights for model VisionTransformer loaded from ../flood-vision/models/vit_b16_2024-02-11 07-01-38_epoch_20.pth\n",
      "\n",
      "Model load time: 37.87 secs\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import time; s = time.time()\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from modules.models_util import ViT\n",
    "\n",
    "weights_path = '../flood-vision/models/vit_b16_2024-02-11 07-01-38_epoch_20.pth'\n",
    "\n",
    "to_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(to_device)\n",
    "\n",
    "model = ViT(device=to_device).load(weights_path.replace('\\\\', '/'))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f'\\nModel load time: {round(time.time() - s, 2)} secs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524dc60e-3bac-45a5-be9f-e25c44b73e92",
   "metadata": {},
   "source": [
    "#### PyTorch model utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20ea4952-adee-441e-b487-d47742c3507f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "def pytorch_predict(batch):\n",
    "    with torch.no_grad(): # no backtracking\n",
    "        output = model(batch)\n",
    "    \n",
    "    probs = F.softmax(output, dim=1)\n",
    "    return probs\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.image_paths[index]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3383ea-20c1-409d-ba2e-1ed2348f6dc2",
   "metadata": {},
   "source": [
    "#### Run predictions with PyTorch in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0798cb65-8917-4ca7-bba3-43d539f09714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/764 | 23.11 min / 185.85 min | time-left: 162.74 min\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from IPython.display import clear_output as co\n",
    "from modules.models_util import ViT\n",
    "\n",
    "base_path = 'data/images'\n",
    "batch_size = 8\n",
    "\n",
    "eval_imgs_df = df_images_sample.sort_values(['id_video', 'frame_index']) # .head(45)\n",
    "img_path_list = f'{base_path}/' + eval_imgs_df['file_path']\n",
    "n_imgs = len(img_path_list)\n",
    "\n",
    "# PyTorch transform\n",
    "transform = ViT.data_transforms['test']\n",
    "\n",
    "# Load images using the custom dataset\n",
    "dataset = CustomDataset(list(img_path_list), transform=transform)\n",
    "\n",
    "# Create a DataLoader for batching and shuffling (if needed)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0) # num_workers different from zero didnt work (got stucked)\n",
    "\n",
    "# Iterate through the data loader\n",
    "preds = []\n",
    "avg_time = 0.0\n",
    "i = 0\n",
    "s_time = time.time()\n",
    "for batch in data_loader:\n",
    "    e_time = time.time() - s_time\n",
    "    e_time_round = round(e_time / 60, 2)\n",
    "    avg_time = e_time / max(1, i)\n",
    "    expected_finish_time = round((n_imgs - i) * avg_time / 60, 2)\n",
    "    expected_total_time = round(n_imgs * avg_time  / 60, 2)\n",
    "\n",
    "    co(True)\n",
    "    print(f'{i}/{n_imgs} | {e_time_round} min / {expected_total_time} min | time-left: {expected_finish_time} min')    \n",
    "    \n",
    "    probs = pytorch_predict(batch)\n",
    "    pred = [[prob.item(), int(prob >= 0.5)] for prob in probs[:, 1]]\n",
    "    preds.extend(pred)\n",
    "    i += len(batch)\n",
    "    \n",
    "eval_imgs_df[['prob', 'pred']] = preds\n",
    "# preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203be138-3b2b-4683-bcf0-afac66d9871d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361110ab-131e-472a-b09e-42bc01331c84",
   "metadata": {},
   "source": [
    "#### Save or reload predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b9a4b91-e3ad-446b-a97f-8adbfb61d742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_directory = 'data/splits/sgkf-8-1-1'\n",
    "# prediction_samples_path = f'{target_directory}/images--cameras-yolo.csv'\n",
    "prediction_samples_path = f'{target_directory}/images-out-cameras-pytorch.csv'\n",
    "\n",
    "eval_imgs_df.to_csv(prediction_samples_path, index=True)\n",
    "\n",
    "# eval_imgs_df = pd.read_csv(prediction_samples_path, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6146506-fff7-48b7-8541-dd231af79433",
   "metadata": {},
   "source": [
    "#### Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d53897ab-c5ad-4fd1-8c2b-7bc6581b2b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " * Confusion Matrix:\n",
      "[[216 168]\n",
      " [238 142]]\n",
      "\n",
      " * Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.56      0.52       384\n",
      "           1       0.46      0.37      0.41       380\n",
      "\n",
      "    accuracy                           0.47       764\n",
      "   macro avg       0.47      0.47      0.46       764\n",
      "weighted avg       0.47      0.47      0.46       764\n",
      "\n",
      "\n",
      " * Jaccard Score:\n",
      "0.2591240875912409\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, jaccard_score\n",
    "\n",
    "labels = eval_imgs_df['flood'].tolist()\n",
    "pred_labels = eval_imgs_df['pred'].tolist()\n",
    "# pred_labels = [pred[0] for pred in preds]\n",
    "\n",
    "print('\\n * Confusion Matrix:')\n",
    "print(confusion_matrix(labels, pred_labels))\n",
    "print('\\n * Classification Report:')\n",
    "print(classification_report(labels, pred_labels))\n",
    "print('\\n * Jaccard Score:')\n",
    "print(jaccard_score(labels, pred_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73f7b9d-fac6-49b8-b256-eec2a637ed37",
   "metadata": {},
   "source": [
    "#### Evaluation per camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "686310e6-f0d0-40b9-ac5b-1970e4401183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " * Confusion_matrix:\n",
      "[[ 0  0]\n",
      " [92 43]]\n",
      "\n",
      " * Classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.32      0.48       135\n",
      "\n",
      "    accuracy                           0.32       135\n",
      "   macro avg       0.50      0.16      0.24       135\n",
      "weighted avg       1.00      0.32      0.48       135\n",
      "\n",
      "\n",
      " * Jaccard Score:\n",
      "0.31851851851851853\n",
      "\n",
      " * Confusion_matrix:\n",
      "[[ 0  0]\n",
      " [65 45]]\n",
      "\n",
      " * Classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.41      0.58       110\n",
      "\n",
      "    accuracy                           0.41       110\n",
      "   macro avg       0.50      0.20      0.29       110\n",
      "weighted avg       1.00      0.41      0.58       110\n",
      "\n",
      "\n",
      " * Jaccard Score:\n",
      "0.4090909090909091\n",
      "\n",
      " * Confusion_matrix:\n",
      "[[53 37]\n",
      " [ 0  0]]\n",
      "\n",
      " * Classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.59      0.74        90\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.59        90\n",
      "   macro avg       0.50      0.29      0.37        90\n",
      "weighted avg       1.00      0.59      0.74        90\n",
      "\n",
      "\n",
      " * Jaccard Score:\n",
      "0.0\n",
      "\n",
      " * Confusion_matrix:\n",
      "[[ 0  0]\n",
      " [56 34]]\n",
      "\n",
      " * Classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.38      0.55        90\n",
      "\n",
      "    accuracy                           0.38        90\n",
      "   macro avg       0.50      0.19      0.27        90\n",
      "weighted avg       1.00      0.38      0.55        90\n",
      "\n",
      "\n",
      " * Jaccard Score:\n",
      "0.37777777777777777\n",
      "\n",
      " * Confusion_matrix:\n",
      "[[30 15]\n",
      " [ 0  0]]\n",
      "\n",
      " * Classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.67      0.80        45\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.67        45\n",
      "   macro avg       0.50      0.33      0.40        45\n",
      "weighted avg       1.00      0.67      0.80        45\n",
      "\n",
      "\n",
      " * Jaccard Score:\n",
      "0.0\n",
      "\n",
      " * Confusion_matrix:\n",
      "[[29 16]\n",
      " [ 0  0]]\n",
      "\n",
      " * Classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.64      0.78        45\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.64        45\n",
      "   macro avg       0.50      0.32      0.39        45\n",
      "weighted avg       1.00      0.64      0.78        45\n",
      "\n",
      "\n",
      " * Jaccard Score:\n",
      "0.0\n",
      "\n",
      " * Confusion_matrix:\n",
      "[[ 0  0]\n",
      " [25 20]]\n",
      "\n",
      " * Classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.44      0.62        45\n",
      "\n",
      "    accuracy                           0.44        45\n",
      "   macro avg       0.50      0.22      0.31        45\n",
      "weighted avg       1.00      0.44      0.62        45\n",
      "\n",
      "\n",
      " * Jaccard Score:\n",
      "0.4444444444444444\n",
      "\n",
      " * Confusion_matrix:\n",
      "[[19 26]\n",
      " [ 0  0]]\n",
      "\n",
      " * Classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.42      0.59        45\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.42        45\n",
      "   macro avg       0.50      0.21      0.30        45\n",
      "weighted avg       1.00      0.42      0.59        45\n",
      "\n",
      "\n",
      " * Jaccard Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luisr\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luisr\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luisr\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luisr\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luisr\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luisr\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luisr\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luisr\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luisr\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luisr\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luisr\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luisr\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luisr\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luisr\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luisr\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luisr\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luisr\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luisr\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luisr\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luisr\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luisr\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luisr\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luisr\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luisr\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "\n",
      " * Confusion_matrix:\n",
      "[[22 23]\n",
      " [ 0  0]]\n",
      "\n",
      " * Classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.49      0.66        45\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.49        45\n",
      "   macro avg       0.50      0.24      0.33        45\n",
      "weighted avg       1.00      0.49      0.66        45\n",
      "\n",
      "\n",
      " * Jaccard Score:\n",
      "0.0\n",
      "\n",
      " * Confusion_matrix:\n",
      "[[24 21]\n",
      " [ 0  0]]\n",
      "\n",
      " * Classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.53      0.70        45\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.53        45\n",
      "   macro avg       0.50      0.27      0.35        45\n",
      "weighted avg       1.00      0.53      0.70        45\n",
      "\n",
      "\n",
      " * Jaccard Score:\n",
      "0.0\n",
      "\n",
      " * Confusion_matrix:\n",
      "[[24 21]\n",
      " [ 0  0]]\n",
      "\n",
      " * Classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.53      0.70        45\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.53        45\n",
      "   macro avg       0.50      0.27      0.35        45\n",
      "weighted avg       1.00      0.53      0.70        45\n",
      "\n",
      "\n",
      " * Jaccard Score:\n",
      "0.0\n",
      "\n",
      " * Confusion_matrix:\n",
      "[[9 8]\n",
      " [0 0]]\n",
      "\n",
      " * Classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.53      0.69        17\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.53        17\n",
      "   macro avg       0.50      0.26      0.35        17\n",
      "weighted avg       1.00      0.53      0.69        17\n",
      "\n",
      "\n",
      " * Jaccard Score:\n",
      "0.0\n",
      "\n",
      " * Confusion_matrix:\n",
      "[[6 1]\n",
      " [0 0]]\n",
      "\n",
      " * Classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.86      0.92         7\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.86         7\n",
      "   macro avg       0.50      0.43      0.46         7\n",
      "weighted avg       1.00      0.86      0.92         7\n",
      "\n",
      "\n",
      " * Jaccard Score:\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luisr\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luisr\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luisr\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luisr\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luisr\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luisr\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luisr\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luisr\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luisr\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luisr\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luisr\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luisr\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luisr\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luisr\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luisr\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "for code in eval_imgs_df['code'].value_counts().index:\n",
    "    code_msk = eval_imgs_df['code'] == code\n",
    "    code_labels = np.array(labels)[code_msk]\n",
    "    code_pred_labels = np.array(pred_labels)[code_msk]\n",
    "\n",
    "    print('\\n * Confusion_matrix:')\n",
    "    print(confusion_matrix(code_labels, code_pred_labels))\n",
    "    print('\\n * Classification_report:')\n",
    "    print(classification_report(code_labels, code_pred_labels))\n",
    "    print('\\n * Jaccard Score:')\n",
    "    print(jaccard_score(code_labels, code_pred_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b9575c-b607-4fa9-8d73-6c9155a6cb34",
   "metadata": {},
   "source": [
    "#### Function to write video results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3483c511-ae42-41ba-86ac-d1d029a0457a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "def create_annotated_video(image_paths, true_labels, predicted_labels, predicted_probs, output_video_path, report=True):\n",
    "    if len(image_paths) != len(true_labels) or len(true_labels) != len(predicted_labels):\n",
    "        raise ValueError(\"Number of paths, true labels, and predicted labels must be the same.\")\n",
    "\n",
    "    # Create a VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video_writer = cv2.VideoWriter(output_video_path, fourcc, 3.0, (854, 480)) # (640, 480)\n",
    "\n",
    "    n_imgs = len(image_paths)\n",
    "    for i, (image_path, true_label, predicted_label, predicted_prob) in enumerate(zip(image_paths, true_labels, predicted_labels, predicted_probs)):\n",
    "        # Read the image\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # Set color based on prediction correctness\n",
    "        if true_label == predicted_label:\n",
    "            color = (0, 255, 0)  # Green for correct predictions\n",
    "        else:\n",
    "            color = (0, 0, 255)  # Red for incorrect predictions\n",
    "\n",
    "        # Annotate the image with true and predicted labels in the bottom-left corner\n",
    "        true_label_text = f'True: {true_label}'\n",
    "        predicted_label_text = f'Predicted: {int(predicted_label)}'\n",
    "        probability_text = f'Probability: {round(predicted_prob * 100, 1)} %'\n",
    "        cv2.putText(image, true_label_text, (image.shape[1] - 130, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2, cv2.LINE_AA)\n",
    "        cv2.putText(image, predicted_label_text, (image.shape[1] - 210, 75), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2, cv2.LINE_AA)\n",
    "        cv2.putText(image, probability_text, (image.shape[1] - 315, 110), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2, cv2.LINE_AA)\n",
    "\n",
    "        # Resize the image for video (optional)\n",
    "        image = cv2.resize(image, (854, 480)) # (640, 480)\n",
    "\n",
    "        # Write the annotated image to the video\n",
    "        video_writer.write(image)\n",
    "\n",
    "        # Report progress\n",
    "        if report:\n",
    "            print(f'Images processed: {i + 1}/{n_imgs} ', end='\\r')    \n",
    "\n",
    "    # Release the VideoWriter\n",
    "    video_writer.release()\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# base_path = 'data/images'\n",
    "\n",
    "# unique_video_ids = eval_imgs_df['id_video'].unique()\n",
    "# video_imgs = eval_imgs_df[eval_imgs_df['id_video']==unique_video_ids[0]]\n",
    "\n",
    "# image_paths = (f'{base_path}/' + video_imgs['file_path']).tolist()\n",
    "# true_labels = video_imgs['flood'].tolist()\n",
    "# predicted_labels = video_imgs['pred'].tolist()\n",
    "# predicted_probs = video_imgs['prob'].tolist()\n",
    "\n",
    "# output_video_path = 'output_video.mp4'\n",
    "\n",
    "# create_annotated_video(image_paths, true_labels, predicted_labels, predicted_probs, output_video_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a063fa2e-1076-4354-8071-94cb989fa62f",
   "metadata": {},
   "source": [
    "#### Write video results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d2d17bc-cad5-42ba-aa3e-b24a23fc2edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cameras processed: 13/13 \r"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "base_path = 'data/images'\n",
    "# base_output_path = 'data/eval-videos-yolo'\n",
    "base_output_path = 'data/eval-videos-pytorch'\n",
    "\n",
    "unique_camera_codes = eval_imgs_df['code'].unique()\n",
    "n_cameras = len(unique_camera_codes)\n",
    "\n",
    "for i, code in enumerate(unique_camera_codes):\n",
    "    for true_label in [0, 1]:\n",
    "        camera_imgs = eval_imgs_df[(eval_imgs_df['code'] == code) & (eval_imgs_df['flood'] == true_label)].sort_values('timestamp')\n",
    "\n",
    "        if not len(camera_imgs):\n",
    "            continue\n",
    "\n",
    "        image_paths = (f'{base_path}/' + camera_imgs['file_path']).tolist()\n",
    "        true_labels = camera_imgs['flood'].tolist()\n",
    "        predicted_labels = camera_imgs['pred'].tolist()\n",
    "        predicted_probs = camera_imgs['prob'].tolist()\n",
    "        output_video_path = f'{base_output_path}/{true_label}/{int(code)}.mp4'\n",
    "        \n",
    "        output_video_dir = os.path.dirname(output_video_path)\n",
    "        if not os.path.isdir(output_video_dir):\n",
    "            os.makedirs(output_video_dir)\n",
    "            \n",
    "        create_annotated_video(image_paths, true_labels, predicted_labels, predicted_probs, output_video_path, report=False)\n",
    "        print(f'Cameras processed: {i + 1}/{n_cameras} ', end='\\r')    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cf49ef-d2c0-4d4e-b3b3-8d7323b5e300",
   "metadata": {},
   "source": [
    "#### End"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b910d5ca-b081-4302-9a83-441c09ba1aea",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4e7b8c-45b2-406e-8dda-8203ca1cd469",
   "metadata": {},
   "source": [
    "### Extra:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562e4a41-3034-4403-aa08-100547fdaef1",
   "metadata": {},
   "source": [
    "#### Load model with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d239213-dbda-46b5-b2b9-0c9af02ddeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model from the saved checkpoint file\n",
    "checkpoint_filepath = 'results/best_model_cnn.h5'\n",
    "model1 = models.load_model(checkpoint_filepath)\n",
    "\n",
    "params = {\n",
    "    'data': 'data/images',\n",
    "    'epochs': 25,\n",
    "    'imgsz': 640,\n",
    "    'batch': 32,\n",
    "    'device': [0, 1],\n",
    "    'learning_rate': 0.0001,\n",
    "}\n",
    "\n",
    "img_height, img_width = 640, 640 # 480, 854\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    params['data'] + '/test',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=params['batch'],\n",
    "    class_mode='binary',\n",
    "    shuffle=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6881bb32-3062-419c-9584-df5e89afeb60",
   "metadata": {},
   "source": [
    "#### Copy images into test folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7b2d9d4-6cf3-4a7c-8f67-8e55c6e48b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Copying images to test folders:\n",
      "Processed 1070/1070 files (100.00%) - Found: 1070/1070\r"
     ]
    }
   ],
   "source": [
    "from modules.octa_video_util import copy_images_to_folders\n",
    "\n",
    "base_directory = 'data/images'\n",
    "target_directory = 'data/splits/sgkf-8-1-1-test-videos'\n",
    "\n",
    "dataset = df_images_sample.copy()\n",
    "file_path_field = 'file_path'\n",
    "label_field = 'flood'\n",
    "\n",
    "train_indexes = None\n",
    "test_indexes = list(df_images_sample.index)\n",
    "val_indexes = None\n",
    "\n",
    "copy_images_to_folders(\n",
    "    base_directory, target_directory, dataset,\n",
    "    train_indexes, test_indexes, val_indexes,\n",
    "    file_path_field=file_path_field, tag_field=label_field\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937acf4b-0c04-4ce1-8312-0dd6e4f737b4",
   "metadata": {},
   "source": [
    "#### Save dataframe of sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "44a0f4c4-8480-4292-af09-93b145f3bb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split dataframe saved with shape: (1070, 13)\n"
     ]
    }
   ],
   "source": [
    "target_directory = 'data/splits/sgkf-8-1-1-videos'\n",
    "\n",
    "dataset = df_images_sample.copy()\n",
    "\n",
    "# data_train = dataset.loc[Y_train.index]\n",
    "data_test = dataset.loc[test_indexes]\n",
    "# data_val = dataset.loc[Y_val.index]\n",
    "\n",
    "# data_train['set'] = 'train'\n",
    "data_test['set'] = 'test'\n",
    "# data_val['set'] = 'val'\n",
    "\n",
    "data_split_df = data_test.copy()\n",
    "# data_split_df = pd.concat([data_train, data_test, data_val])\n",
    "\n",
    "data_split_df.to_csv(f'{target_directory}/images.csv')\n",
    "print(f'split dataframe saved with shape: {data_split_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9323da71-e11b-4e9a-8228-422ccb08a4fd",
   "metadata": {},
   "source": [
    "#### Count save images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8d8d220d-7465-410b-9d40-5eab5df4db24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: 247 823\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "target_directory = 'data/splits/sgkf-8-1-1-videos'\n",
    "\n",
    "# print('train:', len(os.listdir(f'{target_directory}/train/0')), len(os.listdir(f'{target_directory}/train/1')))\n",
    "print('test:', len(os.listdir(f'{target_directory}/test/0')), len(os.listdir(f'{target_directory}/test/1')))\n",
    "# print('val:', len(os.listdir(f'{target_directory}/val/0')), len(os.listdir(f'{target_directory}/val/1')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f2bb58-41ec-4385-866e-ddf613f65201",
   "metadata": {},
   "source": [
    "#### Set up TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f99b42c9-5609-49cf-a850-0f681e002b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not found. Using CPU.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Check if GPU is available\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    print(\"GPU is available.\")\n",
    "    for device in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(device, True)\n",
    "else:\n",
    "    print(\"GPU not found. Using CPU.\")\n",
    "    \n",
    "# Define mirrored strategy for GPU training\n",
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
